[{"authors":null,"categories":null,"content":"图论核心算法全攻略（含 10 大算法 + 场景速选） 图论是数据结构与算法优化的核心模块，也是笔试、面试、期末考试的高频考点。很多学习者的核心痛点是：面对一道图论题，既分不清 “拓扑排序 / 并查集 / DFS” 该选谁，也不知道除了基础 6 大算法外，还有哪些核心算法适配特殊场景。\n本文将系统梳理10 类图论核心算法（包含你指定的拓扑排序、Floyd、Dijkstra、Prim、DFS/BFS、并查集 6 个必选算法，额外补充 4 类高频核心算法），按 “场景特征→最优算法→选择原因→避坑指南” 的逻辑拆解，帮你建立 “看场景选算法” 的思维，无论是期末复习还是实战刷题都能直接套用。\n一、图论算法选择的底层逻辑（先记这 3 步） 选择图论算法无需死记硬背，只需按以下 3 步判断，就能快速锁定最优解：\n定目标：明确问题核心诉求（排序 / 判环？最短路径？连通性？最小生成树？网络流？）； 看图特性：区分图的类型（有向 / 无向？稠密 / 稀疏？边权非负 / 含负权？是否有环？）； 看数据规模：顶点数 n、边数 m 的大小（决定算法效率是否达标，比如 n\u0026gt;100 时 Floyd 会超时）。 二、全场景算法选择对照表（核心精华） 核心场景 典型题型特征 最优算法 包含关系 选择原因 典型例题 关键注意点 有向图排序 + 环检测 1. 有向图；2. 需按依赖关系排序；3. 需判断是否有环（DAG 验证） 拓扑排序（Kahn） 必选 1. 时间复杂度 O (n+m)，适配 n≤1000 的场景；2. 迭代版（队列）避免栈溢出；3. 天然支持环检测 课程表、拓扑排序（DS toplogical sort v1） 1. 1 基顶点转 0 基处理；2. 结果长度≠顶点数 = 有环；3. 入度统计不能遗漏 多源最短路径查询 1. 任意两点间最短路径；2. n≤100（稠密图）；3. 允许负权边（无负权环） Floyd-Warshall 必选 1. 实现最简单（三重循环）；2. 一次性生成所有点对结果；3. O (n³) 仅 n≤100 可行 最短路径（多源查询版） 1. INF 选 10000 避免溢出；2. 循环顺序 k→i→j；3. 松弛前判可达 单源最短路径（边权非负） 1. 单个起点到所有 / 指定终点的最短路径；2. 边权非负；3. n≤200（或堆优化适配更大 n） Dijkstra 必选 1. 贪心策略效率高（基础版 O (n²)，堆优化 O (m log n)）；2. 边权非负时无更优解 畅通工程 3、单源最短路径 1. 边权非负是前提；2. 邻接表版适配稀疏图；3. 无向图双向加边 最小生成树（稠密无向图） 1. 无向图；2. 连接所有顶点且总边权最小；3. 稠密图（边数多，n≤1000） Prim 必选 1. 基础版 O (n²) 适配稠密图；2. 无需排序边，实现更简洁；3. 天然支持连通性判断 公路村村通、畅通工程 2 1. dist 数组是 “到 MST 的最小边权”（区别 Dijkstra）；2. 用访问顶点数判连通 连通分量遍历 / 统计（需顶点） 1. 无向图；2. 需输出连通分量具体顶点；3. 需按指定顺序遍历 DFS/BFS 必选 1. 直观易实现，可控制遍历顺序；2. O (n+m) 适配 n≤1000；3. 兼顾遍历和统计 列出连通集 1. 邻接表排序保证编号递增；2. BFS 入队时标记访问；3. 无向图双向加边 连通性快速查询（大规模） 1. 仅判断两点连通 / 统计分量数；2. 大规模数据（n≤10000）；3. 无需输出具体顶点 并查集（路径压缩 + 秩合） 必选 1. find/union 近似 O (1)，效率远超 DFS/BFS；2. 代码简洁，适配海量边 畅通工程 1、朋友圈 1. 合并前先找根节点；2. 必须路径压缩；3. 统计分量数需调用 find 最小生成树（稀疏无向图） 1. 无向图；2. 连接所有顶点且总边权最小；3. 稀疏图（边数 m\u0026lt;n²） Kruskal 补充 1. 边排序 + 并查集实现，O (m log m) 适配稀疏图；2. 比 Prim 更高效（无需遍历顶点） 最小生成树（稀疏版） 1. 边按权值升序排序；2. 用并查集判环；3. 累计边权直到选够 n-1 条边 单源最短路径（负权边 / 判环） 1. 单个起点最短路径；2. 含负权边；3. 需判断负权环 Bellman-Ford/SPFA 补充 1. 适配负权边场景；2. SPFA 是 Bellman-Ford 优化版，效率更高；3. 可检测负权环 负权边最短路径、判负权环 1. SPFA 用队列实现；2. 用入队次数 \u0026gt; n 判断负权环；3. 避免松弛已确定的顶点 强连通分量 / 割点割边 1. 有向图找强连通分量；2. 无向图找割点 / 割边；3. 需缩点处理 Tarjan 补充 1. 一次 DFS 完成所有计算；2. O (n+m) 适配绝大多数场景；3. 兼顾多种连通问题 强连通分量、网络冗余链路 1. 维护 dfn/low 数组；2. 处理递归栈；3. 无向图需跳过父节点 欧拉路径 / 回路（一笔画） 1. 无向 / 有向图；2. 判断是否存在欧拉路径 / 回路；3. 输出具体路径 Fleury 算法 补充 1. 贪心选边 + 删边实现；2. 直接输出路径；3. 适配 n≤1000 一笔画问题、欧拉回路 1. 先判断度数条件（无向图：0/2 个奇度点）；2. 避免走桥（除非无其他边） 网络最大流 1. 有向图；2. 源点→汇点最大流量；3. 边有容量限制 Dinic 算法 补充 1. 分层图 + DFS 增广，是最大流最优算法；2. O (n²m) 适配绝大多数场景 网络最大流、水流分配 1. 构建残量网络；2. BFS 分层；3. DFS 找增广路并更新残量 三、分算法深度解析（期末 / 实战双适配） （一）必选算法：6 大核心（重点巩固） 1. 拓扑排序（Kahn 算法） 什么时候用？ 只要遇到「有向图依赖排序 + 环检测」场景，优先选拓扑排序，比如：课程安排（先修课→后修课）、任务调度（依赖任务执行顺序）、验证有向图是否为 DAG（无环图）。\n核心优势 迭代版（队列 + 入度）比递归版更稳定，避免顶点数多导致的栈溢出； 时间复杂度 O (n+m)，适配绝大多数高校期末题的 n≤1000 场景； 天然支持环检测（结果长度 \u0026lt; 顶点数 = 有环），无需额外逻辑。 避坑指南 顶点编号：题目常给 1 基顶点，代码中统一转 0 基处理（避免数组越界），输出时再转回 1 基； 入度统计：遍历邻接表时，对每个 u 的邻接顶点 v，必须执行inDegree[v]++，遗漏会导致排序错误； 判环逻辑：不要仅判断队列是否为空，必须用「结果长度 = 顶点数」验证无环。 2. Floyd-Warshall（多源最短路径） 什么时候用？ 需「一次性求任意两点最短路径」，且顶点数 n≤100（稠密图），允许负权边（但无负权环），比如：小范围地图的所有点对最短路径查询。\n核心优势 实现最简单的图论算法之一，仅需三重循环，无需复杂数据结构； 一次性生成所有点对结果，适配批量查询场景（比如连续查询 10 组点对路径）。 避坑指南 INF 取值：绝对不能用Integer.MAX_VALUE（INF+INF 会溢出为负数），选 “略大于题目最大路径和” 的值（如 10000）； 循环顺序：必须先枚举中间点 k，再枚举起点 i、终点 j（k→i→j），顺序错则松弛逻辑完全失效； 松弛前判可达：必须先判断dist[i][k] \u0026lt; INF \u0026amp;\u0026amp; dist[k][j] \u0026lt; INF，否则会用无效值更新路径。 3. Dijkstra（单源最短路径，边权非负） 什么时候用？ 仅需「单个起点到所有 / 指定终点的最短路径」，且边权非负，比如：从北京到上海的最短公路距离、网络中核心节点到其他节点的最小延迟。\n核心优势 贪心策略保证最优解（边权非负时），基础版 O (n²) 适配 n≤200，堆优化版 O (m log n) 适配更大 n； 邻接表版比邻接矩阵版更省内存，适配稀疏图（边数少）。 避坑指南 边权限制：有负权边时绝对不能用（贪心策略失效），需改用 SPFA； 访问标记：BFS 版 Dijkstra 需在入队时标记访问，而非出队时（避免重复入队）； 无向图处理：将无向边视为双向有向边，邻接表中同时添加 u→v 和 v→u。 4. Prim（最小生成树，稠密无向图） 什么时候用？ 无向图中「连接所有顶点且总边权最小」，且是稠密图（边数多），比如：村村通公路（村庄多、道路密）、电网布线（节点密集）。\n核心优势 基础版 O (n²) 适配稠密图，比 Kruskal 更高效（无需排序边）； 天然支持连通性判断：若最终加入 MST 的顶点数≠n，说明图不连通。 避坑指南 关键区别：Prim 的dist数组是「顶点到 MST 的最小边权」，而非 Dijkstra 的「到起点的距离」，切勿混淆； 起点选择：任选一个顶点（如 1）作为起点，最终 MST 总权值不变； 无向图处理：必须双向添加边，否则会漏连连通关系。 5. DFS/BFS（连通分量遍历 / 统计） 什么时候用？ 需要「输出连通分量具体顶点」或「按指定顺序遍历图」，比如：列出所有连通的村庄、按编号递增顺序遍历图的连通区域。\n核心优势 直观易实现，可精准控制遍历顺序（比如对邻接表排序实现编号递增访问）； 既能统计连通分量数，又能输出每个分量的具体顶点，兼顾 “统计” 和 “展示”。 避坑指南 遍历顺序：题目要求 “按编号递增访问邻接顶点” 时，需对每个顶点的邻接表执行Collections.sort()； BFS 标记时机：必须在入队时标记visited[v] = true，而非出队时（避免重复入队导致死循环）； 多组数据：每组数据需重新初始化visited数组，避免前一组数据的标记影响结果。 6. 并查集（连通性快速查询） 什么时候用？ 仅需「判断两点是否连通」或「统计连通分量数」，且数据规模大（n≤10000），比如：畅通工程（计算需建设的最少道路数）、大规模社交网络判断好友关系。\n核心优势 路径压缩 + 按秩合并后，find/union 操作的时间复杂度近似 O (1)，效率远超 DFS/BFS； 代码简洁，内存占用低，适配海量边处理（比如 10 万条边）。 避坑指南 合并逻辑：必须先调用find(a)和find(b)找到根节点，再合并根节点（而非直接合并原顶点）； 路径压缩：查找时必须执行parent[x] = find(parent[x])，否则效率会骤降为 O (n)； 分量统计：统计连通分量数时，需调用find(i)验证是否为根节点，而非直接判断parent[i] == i（路径未压缩时会出错）。 （二）补充算法：4 大高频核心（拓展提分） 1. Kruskal（最小生成树，稀疏无向图） 什么时候用？ 无向图中「连接所有顶点且总边权最小」，且是稀疏图（边数少，比如 n=1000 但 m=2000），比如：城市间建高铁（仅少数城市间有线路）。\n核心思路 步骤 1：将所有边按权值升序排序； 步骤 2：用并查集遍历边，若边的两个顶点不在同一连通分量，则选中该边并合并分量； 步骤 3：直到选中 n-1 条边（生成 MST）或遍历完所有边（图不连通）。 避坑指南 边排序：必须按权值升序排序（保证选的是最小权值边）； 判环逻辑：用并查集判断边的两个顶点是否连通，连通则跳过（避免环）； 终止条件：选中 n-1 条边即可终止（MST 恰好有 n-1 条边），无需遍历所有边。 2. Bellman-Ford/SPFA（单源最短路径，负权边 / 判环） 什么时候用？ 单源最短路径场景中包含负权边，或需要判断是否存在负权环，比如：带手续费的路径规划（手续费为负权）、验证图中是否有负权环（路径长度无限减小）。\n核心思路 Bellman-Ford：对所有边松弛 n-1 次（n 为顶点数），若第 …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766661832,"objectID":"865aef1e5e3886f23b100f5c67517b21","permalink":"https://noctis-sikong.github.io/post/%E5%9B%BE%E8%AE%BA%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95%E5%85%A8%E6%94%BB%E7%95%A5/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E5%9B%BE%E8%AE%BA%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95%E5%85%A8%E6%94%BB%E7%95%A5/","section":"post","summary":"图论核心算法全攻略（含 10 大算法 + 场景速选） 图论是数据结构与算法优化的核心模块，也是笔试、面试、期末考试的高频考点。很多学习者的核心痛点是：面对一道图论题，既分不清 “拓扑排序 / 并查集 / DFS” 该选谁，也不知道除了基础 6 大算法外，还有哪些核心算法适配特殊场景。\n","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"连通性问题 包含DFS/BFS（遍历求连通集）和并查集（Union-Find，连通性查询）\n子分类 1：DFS/BFS（遍历求连通集） 核心场景（详细版） DFS（深度优先搜索）和 BFS（广度优先搜索）是图遍历的基础，用于：\n找出无向图中的所有连通分量（顶点间可达则属于同一分量）； 按指定顺序遍历（如 “从小编号出发，按编号递增访问邻接顶点”）； 典型应用：列出所有连通的村庄、判断图是否连通。 算法思想（详细拆解） DFS（深度优先，递归实现） 核心思想：“先深后广”，从起点出发，递归访问邻接顶点，直到无法深入，再回溯； 步骤： 步骤 1：标记当前顶点为已访问，加入连通分量； 步骤 2：按编号递增顺序遍历当前顶点的邻接顶点； 步骤 3：若邻接顶点未访问，递归访问该顶点。 BFS（广度优先，队列实现） 核心思想：“先广后深”，从起点出发，先访问所有邻接顶点，再访问邻接顶点的邻接顶点； 步骤： 步骤 1：将起点入队，标记为已访问； 步骤 2：循环出队顶点，加入连通分量； 步骤 3：按编号递增顺序遍历出队顶点的邻接顶点，未访问则入队并标记。 通用精简代码（注释清晰，脱离题目限制） import java.util.*; public class ConnectComponent { // DFS：收集单个连通分量 private static void dfs(int u, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; adj, boolean[] visited, List\u0026lt;Integer\u0026gt; component) { visited[u] = true; component.add(u); // 按编号递增访问邻接顶点（题目要求） for (int v : adj.get(u)) { if (!visited[v]) { dfs(v, adj, visited, component); } } } // BFS：收集单个连通分量 private static void bfs(int u, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; adj, boolean[] visited, List\u0026lt;Integer\u0026gt; component) { Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); queue.offer(u); visited[u] = true; while (!queue.isEmpty()) { int cur = queue.poll(); component.add(cur); // 按编号递增访问邻接顶点 for (int v : adj.get(cur)) { if (!visited[v]) { visited[v] = true; queue.offer(v); } } } } // 通用入口：返回所有连通分量 public static List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; getConnectComponents(int n, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; adj, boolean useDFS) { boolean[] visited = new boolean[n]; List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; components = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { if (!visited[i]) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; components = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { if (!visited[i]) { List\u0026lt;Integer\u0026gt; component = new ArrayList\u0026lt;\u0026gt;(); if (useDFS) { dfs(i, adj, visited, component); } else { bfs(i, adj, visited, component); } components.add(component); } } return components; } // 复用入口（适配\u0026#34;列出连通集\u0026#34;） public static void main(String[] args) { Scanner sc = new Scanner(System.in); while (sc.hasNext()) { int n = sc.nextInt(); // 顶点数（0~n-1） int e = sc.nextInt(); // 边数 // 初始化邻接表，邻接顶点按编号排序 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; adj = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) adj.add(new ArrayList\u0026lt;\u0026gt;()); for (int i = 0; i \u0026lt; e; i++) { int u = sc.nextInt(); int v = sc.nextInt(); adj.get(u).add(v); adj.get(v).add(u); // 无向图双向加边 } // 按编号递增排序邻接顶点（满足题目遍历顺序要求） for (int i = 0; i \u0026lt; n; i++) Collections.sort(adj.get(i)); // 1. 输出DFS结果 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; dfsRes = getConnectComponents(n, adj, true); for (List\u0026lt;Integer\u0026gt; comp : dfsRes) printComponent(comp); // 2. 输出BFS结果 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; bfsRes = getConnectComponents(n, adj, false); for (List\u0026lt;Integer\u0026gt; comp : bfsRes) printComponent(comp); } sc.close(); } // 格式化输出连通分量 private static void printComponent(List\u0026lt;Integer\u0026gt; component) { System.out.print(\u0026#34;{ \u0026#34;); for (int i = 0; i \u0026lt; component.size(); i++) { if (i \u0026gt; 0) System.out.print(\u0026#34; \u0026#34;); System.out.print(component.get(i)); } System.out.println(\u0026#34; }\u0026#34;); } } 核心考点（详细解释） 遍历顺序要求：题目常要求 “从小编号出发，按编号递增访问邻接顶点”，需对邻接表排序（Collections.sort (adj.get (u))）； 访问标记时机： DFS：递归前标记（避免重复递归）； BFS：入队时标记（避免重复入队）； 连通分量统计：遍历所有顶点，未访问则启动一次 DFS/BFS，统计启动次数即为连通分量数； 无向图处理：邻接表必须双向加边，否则会漏连通关系。 易错点（详细说明错误原因 + 正确做法） 易错点 错误原因 正确做法 邻接表未排序 访问顺序不符合题目要求 对每个 adj.get (u) 执行 Collections.sort () BFS 出队时才标记 重复入队，导致死循环 / 结果错误 入队时立即标记 visited [v] = true 无向图未双向加边 漏连通关系，连通分量统计错误 同时添加 u→v 和 v→u 的边 多组数据未重置 visited 前一组数据的标记影响后一组 每组数据重新初始化 visited 数组 子分类 2：并查集（Union-Find，连通性查询） 核心场景（详细版） 并查集是高效的连通性查询数据结构，适合以下场景：\n大规模数据（n≤10000）：比 DFS/BFS 更高效（操作接近 O (1)）； 仅需判断连通性 / 统计连通分量数（无需输出具体连通分量）； 典型应用：畅通工程（统计需建设的道路数 = 连通分量数 - 1）。 算法思想（详细拆解） 并查集的核心是「路径压缩 + 按秩合并」，保证操作效率，步骤拆解如下：\n核心概念定义： 父节点数组 parent：parent [x] 表示 x 的父节点，初始时 parent [x] = x（自身为根）； 秩数组 rank：rank [x] 表示以 x 为根的树的高度，用于按秩合并； 根节点：parent [x] = x 的节点（连通分量的代表）。 核心操作： 查找（find）：找节点 x 的根节点，同时执行路径压缩（使 x 直接指向根节点，减少后续查找次数）； 合并（union）：将两个连通分量合并，按秩合并（小秩树合并到大秩树下，减少树高）。 算法步骤： 步骤 1：初始化：parent [x] = x，rank [x] = 0； 步骤 2：处理每条边：将边的两个顶点合并（union (u, v)）； 步骤 3：统计连通分量数：遍历所有顶点，find (x) == x 的顶点数即为连通分量数； 步骤 4：结果计算：需建设的道路数 = 连通分量数 - 1（畅通工程 1 核心）。 通用精简代码（注释清晰，脱离题目限制） import java.io.*; import java.util.StringTokenizer; public class UnionFind { private int[] parent; private int[] rank; // 初始化并查集（1基） public UnionFind(int n) { parent = new int[n + 1]; rank = new int[n + 1]; for (int i = 1; i \u0026lt;= n; i++) { parent[i] = i; // 初始父节点为自身 rank[i] = 0; // 初始秩为0 } } // 查找（递归路径压缩，效率更高） public int find(int x) { if (parent[x] != x) { parent[x] = find(parent[x]); // 路径压缩：x直接指向根节点 } return parent[x]; } // 合并（按秩合并） public void union(int a, int b) { int rootA = find(a); int rootB = find(b); if (rootA == rootB) return; // 已连通，无需合并 // 小秩树合并到大秩树下 if (rank[rootA] \u0026lt; rank[rootB]) { parent[rootA] = rootB; } else { parent[rootB] = rootA; if (rank[rootA] == rank[rootB]) { rank[rootA]++; // 秩相同，合并后根节点秩+1 } } } // 统计连通分量数（根节点数） public int countComponents() { int count = 0; for (int i = 1; i \u0026lt; parent.length; i++) { if (find(i) == i) { // 根节点 count++; } } return count; } // 复用入口（适配\u0026#34;畅通工程1\u0026#34;） public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String line; while ((line = br.readLine()) != null) { StringTokenizer st = new …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766660989,"objectID":"ab753f5963b20e3d717e5a71317f43f0","permalink":"https://noctis-sikong.github.io/post/%E8%BF%9E%E9%80%9A%E6%80%A7%E9%97%AE%E9%A2%98/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E8%BF%9E%E9%80%9A%E6%80%A7%E9%97%AE%E9%A2%98/","section":"post","summary":"连通性问题 包含DFS/BFS（遍历求连通集）和并查集（Union-Find，连通性查询）\n子分类 1：DFS/BFS（遍历求连通集） 核心场景（详细版） DFS（深度优先搜索）和 BFS（广度优先搜索）是图遍历的基础，用于：\n找出无向图中的所有连通分量（顶点间可达则属于同一分量）； 按指定顺序遍历（如 “从小编号出发，按编号递增访问邻接顶点”）； 典型应用：列出所有连通的村庄、判断图是否连通。 算法思想（详细拆解） DFS（深度优先，递归实现） 核心思想：“先深后广”，从起点出发，递归访问邻接顶点，直到无法深入，再回溯； 步骤： 步骤 1：标记当前顶点为已访问，加入连通分量； 步骤 2：按编号递增顺序遍历当前顶点的邻接顶点； 步骤 3：若邻接顶点未访问，递归访问该顶点。 BFS（广度优先，队列实现） 核心思想：“先广后深”，从起点出发，先访问所有邻接顶点，再访问邻接顶点的邻接顶点； 步骤： 步骤 1：将起点入队，标记为已访问； 步骤 2：循环出队顶点，加入连通分量； 步骤 3：按编号递增顺序遍历出队顶点的邻接顶点，未访问则入队并标记。 通用精简代码（注释清晰，脱离题目限制） import java.util.*; public class ConnectComponent { // DFS：收集单个连通分量 private static void dfs(int u, List\u003cList\u003cInteger\u003e\u003e adj, boolean[] visited, List\u003cInteger\u003e component) { visited[u] = true; component.add(u); // 按编号递增访问邻接顶点（题目要求） for (int v : adj.get(u)) { if (!visited[v]) { dfs(v, adj, visited, component); } } } // BFS：收集单个连通分量 private static void bfs(int u, List\u003cList\u003cInteger\u003e\u003e adj, boolean[] visited, List\u003cInteger\u003e component) { Queue\u003cInteger\u003e queue = new LinkedList\u003c\u003e(); queue.offer(u); visited[u] = true; while (!queue.isEmpty()) { int cur = queue.poll(); component.add(cur); // 按编号递增访问邻接顶点 for (int v : adj.get(cur)) { if (!visited[v]) { visited[v] = true; queue.offer(v); } } } } // 通用入口：返回所有连通分量 public static List\u003cList\u003cInteger\u003e\u003e getConnectComponents(int n, List\u003cList\u003cInteger\u003e\u003e adj, boolean useDFS) { boolean[] visited = new boolean[n]; List\u003cList\u003cInteger\u003e\u003e components = new ArrayList\u003c\u003e(); for (int i = 0; i \u003c n; i++) { if (!visited[i]) { List\u003cList\u003cInteger\u003e\u003e components = new ArrayList\u003c\u003e(); for (int i = 0; i \u003c n; i++) { if (!visited[i]) { List\u003cInteger\u003e component = new ArrayList\u003c\u003e(); if (useDFS) { dfs(i, adj, visited, component); } else { bfs(i, adj, visited, component); } components.add(component); } } return components; } // 复用入口（适配\"列出连通集\"） public static void main(String[] args) { Scanner sc = new Scanner(System.in); while (sc.hasNext()) { int n = sc.nextInt(); // 顶点数（0~n-1） int e = sc.nextInt(); // 边数 // 初始化邻接表，邻接顶点按编号排序 List\u003cList\u003cInteger\u003e\u003e adj = new ArrayList\u003c\u003e(); for (int i = 0; i \u003c n; i++) adj.add(new ArrayList\u003c\u003e()); for (int i = 0; i \u003c e; i++) { int u = sc.nextInt(); int v = sc.nextInt(); adj.get(u).add(v); adj.get(v).add(u); // 无向图双向加边 } // 按编号递增排序邻接顶点（满足题目遍历顺序要求） for (int i = 0; i \u003c n; i++) Collections.sort(adj.get(i)); // 1. 输出DFS结果 List\u003cList\u003cInteger\u003e\u003e dfsRes = getConnectComponents(n, adj, true); for (List\u003cInteger\u003e comp : dfsRes) printComponent(comp); // 2. 输出BFS结果 List\u003cList\u003cInteger\u003e\u003e bfsRes = getConnectComponents(n, adj, false); for (List\u003cInteger\u003e comp : bfsRes) printComponent(comp); } sc.close(); } // 格式化输出连通分量 private static void printComponent(List\u003cInteger\u003e component) { System.out.print(\"{ \"); for (int i = 0; i \u003c component.size(); i++) { if (i \u003e 0) System.out.print(\" \"); System.out.print(component.get(i)); } System.out.println(\" }\"); } } 核心考点（详细解释） 遍历顺序要求：题目常要求 “从小编号出发，按编号递增访问邻接顶点”，需对邻接表排序（Collections.sort (adj.get (u))）； 访问标记时机： DFS：递归前标记（避免重复递归）； BFS：入队时标记（避免重复入队）； 连通分量统计：遍历所有顶点，未访问则启动一次 DFS/BFS，统计启动次数即为连通分量数； 无向图处理：邻接表必须双向加边，否则会漏连通关系。 易错点（详细说明错误原因 + 正确做法） 易错点 错误原因 正确做法 邻接表未排序 访问顺序不符合题目要求 对每个 adj.get (u) 执行 Collections.sort () BFS 出队时才标记 重复入队，导致死循环 / 结果错误 入队时立即标记 visited [v] = true 无向图未双向加边 漏连通关系，连通分量统计错误 同时添加 u→v 和 v→u 的边 多组数据未重置 visited 前一组数据的标记影响后一组 每组数据重新初始化 visited 数组 子分类 2：并查集（Union-Find，连通性查询） 核心场景（详细版） 并查集是高效的连通性查询数据结构，适合以下场景：\n","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"Java 实现 AVL 树 一、引言：为什么需要 AVL 树？ 在数据结构的学习中，二叉搜索树（BST）是基础，但普通 BST 存在一个致命问题：如果插入的元素是有序的（比如 1,2,3,4,5），会退化成链表，查询、插入的时间复杂度从O(logn)骤降为O(n)。\nAVL 树（以发明者 Adelson-Velsky 和 Landis 命名）是自平衡二叉搜索树，核心特性是：任意节点的左右子树高度差（平衡因子）的绝对值不超过 1。当插入 / 删除元素导致平衡因子超出范围时，会通过旋转操作重新平衡，保证树的高度始终是O(logn)，从而维持高效的增删查改性能。\n本文将通过完整的 Java 代码，拆解 AVL 树的核心实现（插入、平衡调整、叶子节点统计、三种遍历），既是博客分享，也适配期末复习的考点梳理。\n二、代码整体架构 整个代码分为两部分：\nMain主类：负责读取输入、创建 AVL 树实例、调用核心方法（插入、统计叶子、遍历）； BinarySearchTree类：封装 AVL 树的核心逻辑（节点定义、插入、平衡调整、叶子统计、遍历）。 先看整体代码结构（带复习重点标注）：\nimport java.util.Scanner; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); BinarySearchTree avlTree = new BinarySearchTree(); // 初始化AVL树 // 循环读取输入整数，插入AVL树 while (sc.hasNextInt()) { int v = sc.nextInt(); avlTree.insert(v); } sc.close(); // 1. 输出叶子节点数量 System.out.println(avlTree.leave()); // 2. 前序遍历输出 avlTree.infront(); // 3. 后序遍历输出 avlTree.after(); // 4. 中序遍历输出 avlTree.mid(); } } // AVL树核心类（复习核心） class BinarySearchTree { // 1. 节点内部类（考点：AVL节点需维护高度） private static class TreeNode { int v; // 节点值 TreeNode left; // 左子节点 TreeNode right; // 右子节点 int height; // 节点高度（AVL核心属性，普通BST无此属性） TreeNode(int i) { this.v = i; this.left = null; this.right = null; this.height = 1; // 新节点高度初始为1 } } private TreeNode root; // AVL树根节点 public BinarySearchTree() { this.root = null; // 初始空树 } // 2. 对外暴露的插入方法 public void insert(int v) { this.root = insertBST(this.root, v); } // 3. 插入核心方法（含平衡调整，期末核心考点） public TreeNode insertBST(TreeNode root, int v) { /* 详见下文 */ } // 4. 辅助方法：获取节点高度 private int getHeigh(TreeNode node) { /* 详见下文 */ } // 5. 辅助方法：计算平衡因子（期末核心考点） private int getBalance(TreeNode node) { /* 详见下文 */ } // 6. 旋转操作（左旋转、右旋转，期末核心考点） private TreeNode leftRotate(TreeNode x) { /* 详见下文 */ } private TreeNode rightRotate(TreeNode y) { /* 详见下文 */ } // 7. 统计叶子节点数量（递归，期末常考） public int leave() { /* 详见下文 */ } public int findleave(TreeNode root) { /* 详见下文 */ } // 8. 三种遍历（前序、中序、后序，期末必考） private boolean isFirst = true; // 控制遍历输出格式（无前置空格） public void mid() { /* 中序遍历 */ } public void midprint(TreeNode root) { /* 中序递归逻辑 */ } public void infront() { /* 前序遍历 */ } public void frontprint(TreeNode root) { /* 前序递归逻辑 */ } public void after() { /* 后序遍历 */ } public void afterprint(TreeNode root) { /* 后序递归逻辑 */ } } 三、核心模块逐行解析（复习重点） 模块 1：TreeNode 节点定义（AVL 树的基础） private static class TreeNode { int v; // 节点值 TreeNode left; // 左子节点 TreeNode right; // 右子节点 int height; // 节点高度（★复习重点★） TreeNode(int i) { this.v = i; this.left = null; this.right = null; this.height = 1; // 新节点高度初始为1（叶子节点高度为1） } } 区别于普通 BST：AVL 树的节点必须维护height属性，用于计算平衡因子； 高度定义：叶子节点高度为 1，空节点高度为 0（后续getHeigh方法会处理）； 期末考点：AVL 树节点的核心属性、高度的初始化规则。 模块 2：插入方法（AVL 树的核心，含平衡调整） 插入逻辑分为两步：① 普通 BST 的插入；② 调整高度 + 检查平衡 + 旋转平衡。\n步骤 1：普通 BST 插入 public TreeNode insertBST(TreeNode root, int v) { // 1. 普通BST插入逻辑（递归终止条件：空节点则创建新节点） if (root == null) { return new TreeNode(v); } // 小于根节点：插入左子树 if (v \u0026lt; root.v) { root.left = insertBST(root.left, v); } // 大于根节点：插入右子树 else if (v \u0026gt; root.v) { root.right = insertBST(root.right, v); } // 等于根节点：AVL树不存重复值，直接返回 else { return root; } 递归插入：符合 BST 的核心规则（左子树 \u0026lt; 根 \u0026lt; 右子树）； 去重：重复值直接返回，不插入（AVL 树通常不存储重复元素）。 步骤 2：更新当前节点高度 // 2. 更新当前节点的高度（★复习重点★） root.height = 1 + Math.max(getHeigh(root.left), getHeigh(root.right)); 高度计算公式：当前节点高度 = 1 + 左右子树高度的最大值；\n辅助方法getHeigh：处理空节点的高度（空节点高度为 0）：\nprivate int getHeigh(TreeNode node) { return node == null ? 0 : node.height; } 步骤 3：计算平衡因子，判断是否失衡 // 3. 计算平衡因子（★期末核心考点★） int balance = getBalance(root); // 平衡因子 = 左子树高度 - 右子树高度 private int getBalance(TreeNode node) { if (node == null) { return 0; } return getHeigh(node.left) - getHeigh(node.right); } 平衡因子定义：平衡因子 = 左子树高度 - 右子树高度； 失衡判定：平衡因子的绝对值 \u0026gt; 1 时，需要旋转调整； 期末考点：平衡因子的计算公式、失衡的判定条件。 步骤 4：四种失衡情况的旋转调整（★期末重中之重★） AVL 树的四种失衡情况对应四种旋转策略，核心是 “左旋” 和 “右旋” 两个基础操作，组合解决所有失衡：\n失衡类型 平衡因子 插入位置 旋转策略 左左型（LL） \u0026gt;1 左子树的左子树 右旋 右右型（RR） \u0026lt; -1 右子树的右子树 左旋 左右型（LR） \u0026gt;1 左子树的右子树 左子树左旋 + 根右旋 右左型（RL） \u0026lt; -1 右子树的左子树 右子树右旋 + 根左旋 // 4. 旋转调整（四种失衡情况） // 情况1：LL型（左左）→ 右旋 if (balance \u0026gt; 1 \u0026amp;\u0026amp; v \u0026lt; root.left.v) { return rightRotate(root); } // 情况2：RR型（右右）→ 左旋 if (balance \u0026lt; -1 \u0026amp;\u0026amp; v \u0026gt; root.right.v) { return leftRotate(root); } // 情况3：LR型（左右）→ 左子树左旋 + 根右旋 if (balance \u0026gt; 1 \u0026amp;\u0026amp; v \u0026gt; root.left.v) { root.left = leftRotate(root.left); return rightRotate(root); } // 情况4：RL型（右左）→ 右子树右旋 + 根左旋 if (balance \u0026lt; -1 \u0026amp;\u0026amp; v \u0026lt; root.right.v) { root.right = rightRotate(root.right); return leftRotate(root); } // 未失衡：直接返回当前节点 return root; } 基础旋转操作解析： 右旋（解决 LL 型失衡）： private TreeNode rightRotate(TreeNode y) { // 步骤1：定义临时节点 TreeNode x = y.right; // 错误修正：原代码笔误，正确应为 TreeNode x = y.left; TreeNode xLeft = x.right; // 步骤2：旋转核心 x.left = y; y.right = xLeft; // 步骤3：更新高度（先更新下层节点y，再更新上层节点x） y.height = 1 + Math.max(getHeigh(y.left), getHeigh(y.right)); x.height = 1 + Math.max(getHeigh(x.left), getHeigh(x.right)); // 返回新的根节点（x成为新根） return x; } ⚠️ 注：原代码中rightRotate方法有笔误（TreeNode x = y.right应为TreeNode x = y.left），已修正，复习时需注意！\n左旋（解决 RR 型失衡）： private TreeNode leftRotate(TreeNode x) { // 步骤1：定义临时节点 TreeNode y = x.left; // 错误修正：原代码笔误，正确应为 TreeNode y = x.right; TreeNode yRight = y.right; // 步骤2：旋转核心 …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766657885,"objectID":"b9d6d07621773071c27066ffd0f4059f","permalink":"https://noctis-sikong.github.io/post/avl-%E6%A0%91/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/avl-%E6%A0%91/","section":"post","summary":"Java 实现 AVL 树 一、引言：为什么需要 AVL 树？ 在数据结构的学习中，二叉搜索树（BST）是基础，但普通 BST 存在一个致命问题：如果插入的元素是有序的（比如 1,2,3,4,5），会退化成链表，查询、插入的时间复杂度从O(logn)骤降为O(n)。\n","tags":null,"title":"AVL树","type":"post"},{"authors":null,"categories":null,"content":"二叉树构建与遍历题型全解 一、核心算法思想总览 这 4 道题本质是分治思想在二叉树中的应用，核心逻辑高度统一 —— 无论给定哪两种遍历序列，都以「中序序列为分割依据，另一种序列定根节点」，通过 “拆分问题→递归求解子问题→合并结果” 构建二叉树，再按需执行遍历或反转操作。\n通用分治框架（贯穿所有题型） 找根节点：从非中序序列（前序 / 后序 / 层序）中定位当前子树的根（不同序列根节点位置不同）； 分割子树：在中序序列中找到根节点位置，将中序序列拆分为「左子树中序序列」和「右子树中序序列」，确定左右子树节点数； 递归构建：根据左右子树节点数，拆分非中序序列，递归构建左、右子树； 合并结果：当前根节点连接左右子树，形成完整二叉树。 辅助算法思想 遍历思想：前 / 中 / 后序用深度优先搜索（DFS，递归实现），层序用广度优先搜索（BFS，队列实现）； 镜面反转：本质是后序 DFS—— 先递归反转子树，再交换当前节点左右子树（或先交换再递归，结果一致）。 二、通用基础模块（算法思想落地 + 优化代码） 1. 二叉树节点定义（极简核心版） 算法思想：节点是二叉树的基本单位，仅需存储值、左子节点、右子节点，无需冗余属性（如 AVL 树的 height），聚焦构建与遍历核心。\nprivate static class TreeNode { int val; // 节点值，统一命名val，比v更易读 TreeNode left; // 左子节点 TreeNode right; // 右子节点 TreeNode(int val) { this.val = val; this.left = null; this.right = null; } } 2. 通用工具方法（规避重复代码，适配所有题型） （1）输入处理 算法思想：统一读取整数数组，避免sc.nextLine()吞换行的坑，适配多组输入场景。\nprivate static int[] readIntArray(Scanner sc, int n) { int[] arr = new int[n]; for (int i = 0; i \u0026lt; n; i++) { arr[i] = sc.nextInt(); } return arr; } （2）遍历结果收集（DFS 思想落地） 算法思想：用列表收集遍历结果，替代直接打印，兼顾格式控制与灵活性，符合 DFS“先访问节点，再递归子树” 的逻辑。\n// 前序遍历收集（根→左→右） private static void preCollect(TreeNode root, List\u0026lt;Integer\u0026gt; res) { if (root == null) return; // DFS终止条件：空节点无数据 res.add(root.val); // 访问根 preCollect(root.left, res); // 递归左子树 preCollect(root.right, res); // 递归右子树 } // 后序遍历收集（左→右→根） private static void postCollect(TreeNode root, List\u0026lt;Integer\u0026gt; res) { if (root == null) return; postCollect(root.left, res); // 递归左子树 postCollect(root.right, res); // 递归右子树 res.add(root.val); // 访问根 } （3）结果格式输出 算法思想：统一控制 “空格分隔、首尾无多余空格”，避免重复编写格式逻辑。\nprivate static void printList(List\u0026lt;Integer\u0026gt; list) { for (int i = 0; i \u0026lt; list.size(); i++) { if (i \u0026gt; 0) System.out.print(\u0026#34; \u0026#34;); System.out.print(list.get(i)); } System.out.println(); } 三、分题型解析（算法思想 + 代码 + 考点） 题型 1：玩转二叉树（前序 + 中序→构建→镜面反转→层序） 核心算法思想 构建思想（分治）：前序序列第一个元素是根→中序分左右子树→按左子树节点数拆分前序序列→递归构建； 镜面反转思想（DFS）：遍历每个节点，交换其左右子树，再递归反转子树（本质是 “后序遍历” 逻辑，先处理子树再处理当前节点）； 层序遍历思想（BFS）：用队列维护当前层节点，出队时访问，同时入队左右子节点，保证 “逐层访问” 顺序。 优化代码 import java.util.*; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int[] inOrder = readIntArray(sc, n); // 中序序列（分割依据） int[] preOrder = readIntArray(sc, n); // 前序序列（定根依据） sc.close(); // 分治构建二叉树 TreeNode root = buildFromPreAndIn(preOrder, 0, n-1, inOrder, 0, n-1); // DFS镜面反转 reverseTree(root); // BFS层序遍历 List\u0026lt;Integer\u0026gt; res = levelOrder(root); // 格式输出 printList(res); } // 分治：前序+中序构建二叉树 private static TreeNode buildFromPreAndIn(int[] pre, int preL, int preR, int[] in, int inL, int inR) { if (preL \u0026gt; preR || inL \u0026gt; inR) return null; // 分治终止：子树为空 // 步骤1：找根节点（前序第一个元素） int rootVal = pre[preL]; TreeNode root = new TreeNode(rootVal); // 步骤2：中序分割左右子树 int rootIdx = -1; for (int i = inL; i \u0026lt;= inR; i++) { if (in[i] == rootVal) { rootIdx = i; break; } } int leftSize = rootIdx - inL; // 左子树节点数（分治关键：确定子问题规模） // 步骤3：递归构建左右子树（分治求解子问题） root.left = buildFromPreAndIn(pre, preL+1, preL+leftSize, in, inL, rootIdx-1); root.right = buildFromPreAndIn(pre, preL+leftSize+1, preR, in, rootIdx+1, inR); return root; // 合并结果：返回当前子树根 } // DFS：镜面反转二叉树 private static void reverseTree(TreeNode root) { if (root == null) return; // DFS终止 // 交换当前节点左右子树 TreeNode temp = root.left; root.left = root.right; root.right = temp; // 递归反转子树（处理子问题） reverseTree(root.left); reverseTree(root.right); } // BFS：层序遍历 private static List\u0026lt;Integer\u0026gt; levelOrder(TreeNode root) { List\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (root == null) return res; Queue\u0026lt;TreeNode\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); queue.offer(root); // 根节点入队（初始化当前层） while (!queue.isEmpty()) { TreeNode node = queue.poll(); // 出队访问 res.add(node.val); // 左右子节点入队（维护下一层） if (node.left != null) queue.offer(node.left); if (node.right != null) queue.offer(node.right); } return res; } // 通用工具方法（输入+输出） private static int[] readIntArray(Scanner sc, int n) { /* 同前文，省略重复代码 */ } private static void printList(List\u0026lt;Integer\u0026gt; list) { /* 同前文，省略重复代码 */ } } 期末考点 分治思想在 “前序 + 中序构建” 中的落地（根定位、子树分割）； BFS 实现层序遍历的队列用法； 镜面反转的 DFS 逻辑（交换左右子树的时机）。 题型 2：Tree Traversals Again and Again（层序 + 中序→构建→前序 + 后序） 核心算法思想 构建思想（分治 + 筛选）：层序第一个元素是根→中序分左右子树→从层序剩余元素中 “筛选” 出属于左 / 右子树的节点（按中序区间判断）→递归构建； 遍历思想：前序 / 后序均为 DFS，仅访问节点的时机不同（根的位置不同）。 优化代码 import java.util.*; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int[] levelOrder = readIntArray(sc, n); // 层序序列（定根依据） int[] inOrder = readIntArray(sc, n); // 中序序列（分割+筛选依据） sc.close(); // 分治+筛选构建二叉树 TreeNode root = buildFromLevelAndIn(levelOrder, inOrder, 0, n-1); // DFS收集前序、后序结果 List\u0026lt;Integer\u0026gt; preRes = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; postRes = new ArrayList\u0026lt;\u0026gt;(); preCollect(root, preRes); postCollect(root, postRes); // 输出 printList(preRes); printList(postRes); } // 分治+筛选：层序+中序构建二叉树 private static TreeNode buildFromLevelAndIn(int[] level, int[] in, int inL, int inR) { if (level.length == 0 || inL \u0026gt; inR) return null; // 分治终止 // 步骤1：找根节点（层序第一个元素） int rootVal = level[0]; TreeNode root = new TreeNode(rootVal); // 步骤2：中序分割左右子树 int rootIdx = -1; for (int i = inL; i \u0026lt;= inR; i++) { …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766658960,"objectID":"8c703f913480143f6f221a597308adb5","permalink":"https://noctis-sikong.github.io/post/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%81%8D%E5%8E%86/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%81%8D%E5%8E%86/","section":"post","summary":"二叉树构建与遍历题型全解 一、核心算法思想总览 这 4 道题本质是分治思想在二叉树中的应用，核心逻辑高度统一 —— 无论给定哪两种遍历序列，都以「中序序列为分割依据，另一种序列定根节点」，通过 “拆分问题→递归求解子问题→合并结果” 构建二叉树，再按需执行遍历或反转操作。\n通用分治框架（贯穿所有题型） 找根节点：从非中序序列（前序 / 后序 / 层序）中定位当前子树的根（不同序列根节点位置不同）； 分割子树：在中序序列中找到根节点位置，将中序序列拆分为「左子树中序序列」和「右子树中序序列」，确定左右子树节点数； 递归构建：根据左右子树节点数，拆分非中序序列，递归构建左、右子树； 合并结果：当前根节点连接左右子树，形成完整二叉树。 辅助算法思想 遍历思想：前 / 中 / 后序用深度优先搜索（DFS，递归实现），层序用广度优先搜索（BFS，队列实现）； 镜面反转：本质是后序 DFS—— 先递归反转子树，再交换当前节点左右子树（或先交换再递归，结果一致）。 二、通用基础模块（算法思想落地 + 优化代码） 1. 二叉树节点定义（极简核心版） 算法思想：节点是二叉树的基本单位，仅需存储值、左子节点、右子节点，无需冗余属性（如 AVL 树的 height），聚焦构建与遍历核心。\n","tags":null,"title":"二叉树构建与遍历","type":"post"},{"authors":null,"categories":null,"content":"前 m 大数值筛选（二分答案 + 局部排序） 一、题目核心分析与算法思想 1. 题目特点 给定 n 个整数（0 \u0026lt;n,m \u0026lt; 1e6），数值范围 [-500000,500000]，要求输出前 m 大的数（降序）。\n关键限制：n/m 规模接近 1e6，不能用整体排序（如 Arrays.sort 整体 O (n log n)）或冒泡排序（O (m²)），否则超时；\n核心思路：利用「二分答案法」找到第 m 大的数，仅收集前 m 个数做局部排序，将时间复杂度从 O (n log n) 优化为 O (n log (数值范围)) + O (m log m)，适配大规模数据。\n2. 核心算法思想 算法思想 应用场景 核心逻辑 二分答案（二分查找） 找第 k 大 / 小值、数值范围有限的场景 对数值范围二分，通过「统计大于当前中间值的数的个数」判断第 m 大值的位置 计数统计 快速判断数值分布 统计大于 / 等于某个值的数的个数，辅助二分判断 局部排序 大规模数据筛选后排序 仅对前 m 个数排序，而非整体排序，减少排序规模 快速 IO 百万级数据输入输出 用 BufferedReader/PrintWriter 替代 Scanner/System.out，避免 IO 超时 二、算法步骤拆解（配优化代码） 1. 完整优化代码（思想标注 + 命名规范 + 性能优化） import java.io.*; import java.util.Arrays; class Main { public static void main(String[] s) throws Exception { // 快速IO：百万级数据必须用BufferedReader/PrintWriter，避免Scanner超时 BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); PrintWriter pw = new PrintWriter(new OutputStreamWriter(System.out)); String line; while ((line = br.readLine()) != null) { // 步骤1：读取n和m String[] nm = line.trim().split(\u0026#34; \u0026#34;); int n = Integer.parseInt(nm[0]); int m = Integer.parseInt(nm[1]); // 步骤2：读取数组，同时确定数值范围（二分的左右边界） String[] valStr = br.readLine().trim().split(\u0026#34; \u0026#34;); int[] arr = new int[n]; int minVal = 500000; // 数值下界 int maxVal = -500000; // 数值上界 for (int i = 0; i \u0026lt; n; i++) { arr[i] = Integer.parseInt(valStr[i]); minVal = Math.min(minVal, arr[i]); maxVal = Math.max(maxVal, arr[i]); } // 步骤3：二分答案找「第m大的数target」 int left = minVal, right = maxVal; int target = 0; while (left \u0026lt;= right) { int mid = (left + right) / 2; // 统计大于mid的数的个数（核心：判断mid是否小于第m大的数） int countGreater = countGreaterThan(arr, mid); if (countGreater \u0026gt;= m) { // 大于mid的数≥m个 → 第m大的数在mid右侧 left = mid + 1; } else { // 统计等于mid的数的个数 int countEqual = countEqual(arr, mid); if (countGreater + countEqual \u0026gt;= m) { // 大于+等于mid的数≥m个 → mid就是第m大的数 target = mid; break; } else { // 第m大的数在mid左侧 right = mid - 1; } } } // 步骤4：收集前m大的数（先收集大于target的，再补等于target的） int[] result = new int[m]; int idx = 0; // 先加大于target的数 for (int num : arr) { if (num \u0026gt; target \u0026amp;\u0026amp; idx \u0026lt; m) { result[idx++] = num; } } // 补等于target的数（凑够m个） if (idx \u0026lt; m) { for (int num : arr) { if (num == target \u0026amp;\u0026amp; idx \u0026lt; m) { result[idx++] = num; } } } // 步骤5：局部排序（降序）→ 替换原冒泡排序，用Arrays.sort+反转，O(m log m)更高效 Arrays.sort(result); reverseArray(result); // 升序转降序 // 步骤6：输出结果（格式控制：首尾无空格） for (int i = 0; i \u0026lt; m; i++) { if (i \u0026gt; 0) pw.print(\u0026#34; \u0026#34;); pw.print(result[i]); } pw.println(); } // 释放资源 pw.flush(); pw.close(); br.close(); } // 辅助：统计数组中大于num的数的个数（O(n)） private static int countGreaterThan(int[] arr, int num) { int count = 0; for (int val : arr) { if (val \u0026gt; num) count++; } return count; } // 辅助：统计数组中等于num的数的个数（O(n)） private static int countEqual(int[] arr, int num) { int count = 0; for (int val : arr) { if (val == num) count++; } return count; } // 辅助：数组反转（升序转降序） private static void reverseArray(int[] arr) { int left = 0, right = arr.length - 1; while (left \u0026lt; right) { int temp = arr[left]; arr[left] = arr[right]; arr[right] = temp; left++; right--; } } } 2. 关键步骤解析（算法思想落地） （1）快速 IO 处理（百万级数据必备） 思想：Scanner/System.out.println 在百万级数据下会超时，BufferedReader 按行读取、PrintWriter 批量输出，IO 效率提升 10 倍以上； 代码要点：br.readLine()读取整行，trim()去除首尾空格，split(\u0026#34; \u0026#34;)分割字符串。 （2）二分答案找第 m 大的数（核心） 思想：「二分答案」是将 “找第 m 大值” 转化为 “判断某个值是否是第 m 大值”，通过数值范围（[-5e5,5e5]）二分，每次判断仅需 O (n)，总时间 O (n log 1e6) ≈ O (n*20)，远快于整体排序； 逻辑拆解： 二分边界：left = 数组最小值，right = 数组最大值； 中间值 mid：判断 “大于 mid 的数的个数 countGreater”； 分支 1（countGreater ≥ m）：说明第 m 大的数比 mid 大，左边界右移（left=mid+1）； 分支 2（countGreater \u0026lt; m）：统计等于 mid 的数 countEqual，若 countGreater+countEqual ≥ m → mid 就是第 m 大的数；否则右边界左移（right=mid-1）。 （3）收集前 m 大的数 思想：先收集所有大于 target 的数（这些数一定在前 m 大里），再补等于 target 的数（凑够 m 个），避免收集无关数据； 注意：无需收集小于 target 的数，因为 target 是第 m 大的数，小于它的数不可能进入前 m。 （4）局部排序优化 原问题：原代码用冒泡排序（O (m²)），m=1e6 时完全超时； 优化方案：用 Arrays.sort（O (m log m)）先升序排序，再反转数组得到降序，时间复杂度从 O (m²) 降到 O (m log m)，适配大规模 m。 三、期末复习核心考点 1. 算法思想考点 考点 核心提问方式 解题关键 二分答案法 如何找第 k 大 / 小值？为什么不用整体排序？ 数值范围有限时，二分答案 + 计数统计，时间复杂度更低（O (n log 数值范围)） 大规模数据 IO 优化 百万级数据输入输出为什么超时？ 必须用 BufferedReader/PrintWriter，避免 Scanner/System.out 的逐字符处理 局部排序 为什么只对前 m 个数排序？ 整体排序 O (n log n)，局部排序 O (m log m)，m\u0026lt;n 时大幅减少计算量 2. 易错点总结（期末避坑） 二分边界错误： 忘记统计 “等于 mid 的数”，直接用 countGreater 判断，导致漏判 target； 二分终止条件写成left \u0026lt; right，可能导致 target 未找到； IO 超时： 用 Scanner 读取百万级数据，或用 System.out.println 逐行输出； 排序效率： 对 m=1e6 的数组用冒泡排序，时间复杂度爆炸； 数值范围： 初始化 minVal/maxVal 时写反（比如 minVal 初始 - 5e5，maxVal 初始 5e5），导致二分边界错误。 3. 同类题型扩展（举一反三） 题型 核心思想复用 差异点 找第 k 小的数 二分答案 + 计数统计 统计 “小于 mid 的数的个数”，而非 “大于” 数值范围 [-1e9,1e9] 二分答案依然可用 需先遍历数组确定 min/max，而非硬编码数值范围 有重复数的前 m 大 收集时需包含重复的 target 本题已兼容，无需额外修改 四、复习建议 背记二分答案模板：\nint left = 最小值, right = 最大值; int target = 0; while (left \u0026lt;= right) { int mid = (left + right) / 2; int count = 统计符合条件的数; if (count \u0026gt;= m) { left = mid + 1; } else { // 补充等于mid的统计，判断是否找到target } } 手动模拟样例：\n样例输入 1：5 3，数组 [3,-35,92,213,-644] 数值范围：-644~213 二分找到 target=3（第 3 大的数） 收集大于 3 的数：213、92，再补等于 3 的数，凑够 3 个； 排序后输出：213 92 3； 重点记忆 IO 优化和局部排序：\n快速 IO 的固定写法（BufferedReader+PrintWriter）； Arrays.sort + 反转实现降序的固定逻辑。 五、核心总结 这道题的核心是「用二分答案替代整体排序」，适配大规模数据场景：\n二分答案找第 m 大值，将时间复杂度从 O (n log n) 降到 O (n …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766658931,"objectID":"8ba6b0fc69929dd44df55535305024d1","permalink":"https://noctis-sikong.github.io/post/%E5%89%8D-m-%E5%A4%A7%E6%95%B0%E5%80%BC%E7%AD%9B%E9%80%89/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E5%89%8D-m-%E5%A4%A7%E6%95%B0%E5%80%BC%E7%AD%9B%E9%80%89/","section":"post","summary":"前 m 大数值筛选（二分答案 + 局部排序） 一、题目核心分析与算法思想 1. 题目特点 给定 n 个整数（0 \u003cn,m \u003c 1e6），数值范围 [-500000,500000]，要求输出前 m 大的数（降序）。\n","tags":null,"title":"前 m 大数值筛选","type":"post"},{"authors":null,"categories":null,"content":"拓扑排序（Topological Sort） 核心场景（详细版） 拓扑排序仅适用于有向无环图（DAG），核心目标是对顶点进行线性排序，满足「若存在从顶点 i 到顶点 j 的有向路径，则 i 在排序结果中一定出现在 j 之前」。\n典型应用：任务调度（依赖任务必须先执行）、课程安排（先修课需先学）；\n额外需求：若图中存在环（非 DAG），则无法完成拓扑排序，需输出 “not acyclic” 或返回空。\n算法思想（详细拆解，Kahn 算法 —— 迭代版最优） Kahn 算法是拓扑排序的经典迭代实现（比递归版更稳定，避免栈溢出），核心围绕「入度」展开，步骤拆解如下：\n核心概念定义： 入度（In-Degree）：指向某顶点的边的数量（如顶点 v 有 3 条入边，则入度为 3）； 入度为 0 的顶点：无前置依赖，可作为排序的起点。 算法步骤： 步骤 1：统计所有顶点的入度（构建入度数组）。遍历邻接表，对每个顶点 u 的邻接顶点 v，v 的入度 + 1（因为 u→v 是一条入边）。 步骤 2：初始化队列，将所有「入度为 0」的顶点入队（这些顶点无前置依赖，可优先处理）。 步骤 3：循环处理队列中的顶点： 取出队首顶点 u，加入排序结果； 遍历 u 的所有邻接顶点 v：将 v 的入度 - 1（因为 u 已处理，v 的一个前置依赖已完成）； 若 v 的入度减为 0，将 v 入队（v 的所有前置依赖已完成，可处理）。 步骤 4：判环逻辑：若最终排序结果的顶点数 ≠ 总顶点数，说明图中存在环（环内顶点的入度永远无法减为 0，不会被加入结果）。 通用精简代码（注释清晰，脱离题目限制） import java.util.*; public class TopologicalSort { // 通用拓扑排序：返回排序结果（空列表表示有环） // 参数：n=顶点数（0~n-1），adj=邻接表（adj[u]存储u的所有出边顶点v） public static List\u0026lt;Integer\u0026gt; topologicalSort(int n, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; adj) { int[] inDegree = new int[n]; // 入度数组 // 步骤1：统计入度 for (int u = 0; u \u0026lt; n; u++) { for (int v : adj.get(u)) { inDegree[v]++; } } // 步骤2：入度为0的顶点入队 Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { if (inDegree[i] == 0) { queue.offer(i); } } // 步骤3：核心排序逻辑 List\u0026lt;Integer\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); while (!queue.isEmpty()) { int u = queue.poll(); result.add(u); // 处理u的邻接顶点，入度减1 for (int v : adj.get(u)) { inDegree[v]--; if (inDegree[v] == 0) { queue.offer(v); } } } // 步骤4：判环（结果长度≠顶点数 → 有环） return result.size() == n ? result : Collections.emptyList(); } // 复用入口（适配各类拓扑排序题） public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); // 顶点数 int m = sc.nextInt(); // 边数 // 初始化邻接表（通用0基，题目若1基则转换） List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; adj = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) adj.add(new ArrayList\u0026lt;\u0026gt;()); for (int i = 0; i \u0026lt; m; i++) { int u = sc.nextInt() - 1; // 1基转0基（按需调整） int v = sc.nextInt() - 1; adj.get(u).add(v); } List\u0026lt;Integer\u0026gt; res = topologicalSort(n, adj); if (res.isEmpty()) { System.out.println(\u0026#34;not acyclic\u0026#34;); // 判环输出 } else { // 输出：0基转回1基（按需调整） for (int i = 0; i \u0026lt; res.size(); i++) { if (i \u0026gt; 0) System.out.print(\u0026#34; \u0026#34;); System.out.print(res.get(i) + 1); } } sc.close(); } } 核心考点（详细解释） 算法效率：时间复杂度 O (n+m)（n = 顶点数，m = 边数），每个顶点和边仅处理一次，是拓扑排序的最优复杂度； 判环逻辑本质：环内的所有顶点入度永远无法减为 0（环内顶点互相依赖），因此不会被加入结果，结果长度小于总顶点数； 迭代版 vs 递归版：递归版（基于 DFS 后序遍历）易因顶点数过多（如 n\u0026gt;1000）导致栈溢出，优先用 Kahn 迭代版； 顶点编号适配：题目中顶点可能从 1 开始（如样例输入），代码中统一转 0 基处理（避免数组越界），输出时再转回 1 基。 易错点（详细说明错误原因 + 正确做法） 易错点 错误原因 正确做法 入度统计遗漏 仅遍历边的起点，未更新终点入度 遍历 adj [u] 的每个 v，执行 inDegree [v]++ 顶点编号未转换 题目 1 基，代码用 0 基导致数组越界 输入时 u/v-1 转 0 基，输出时 + 1 转回 1 基 判环逻辑错误 仅判断队列是否为空，未校验结果长度 必须用 result.size () == n 判断是否有环 递归版栈溢出 顶点数多（如 n=10000） 改用 Kahn 迭代版（队列实现） 总结（辅助记忆） 拓扑排序核心口诀：「入度为 0 入队 → 处理顶点减邻接入度 → 入度为 0 再入队 → 结果长度判环」；\n核心数据结构：入度数组 + 队列；\n核心适用场景：DAG 排序、依赖调度、判环。\n","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766660282,"objectID":"33730cd1ead8c19fdc23cc0ba2530537","permalink":"https://noctis-sikong.github.io/post/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8Ftopological-sort/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8Ftopological-sort/","section":"post","summary":"拓扑排序（Topological Sort） 核心场景（详细版） 拓扑排序仅适用于有向无环图（DAG），核心目标是对顶点进行线性排序，满足「若存在从顶点 i 到顶点 j 的有向路径，则 i 在排序结果中一定出现在 j 之前」。\n","tags":null,"title":"拓扑排序（Topological Sort）","type":"post"},{"authors":null,"categories":null,"content":"「左侧最大 + 右侧最小」元素筛选 一、题目核心分析与算法思想 1. 题目功能定义（默认输入为正数） 给定长度为 n 的正整数数组，筛选出满足以下条件的元素（「递增关键元素」）：\n第一个元素：大于左侧所有元素的最大值（左侧无元素，最大值为 0）且小于右侧所有元素的最小值；\n中间元素（非首尾）：大于左侧所有元素的最大值 且 小于右侧所有元素的最小值；\n最后一个元素：仅需大于左侧所有元素的最大值；\n最终输出满足条件的元素个数，以及这些元素（按原顺序，空格分隔）。\n2. 核心算法思想对比 实现方式 算法思想 时间复杂度 适用场景 核心优化点 原代码 实时计算右侧最小值 O(n²) 小规模正整数数组 无，重复计算超时 正数专用版 预处理（前缀最大 + 后缀最小） O(n) 仅正整数数组 初始值简化为 0/MAX 通用推广版 预处理（前缀最大 + 后缀最小） O(n) 任意整数数组（含负数） 初始值兼容所有数值 核心思想：空间换时间—— 通过提前预处理「前缀最大值数组」和「后缀最小值数组」，避免遍历每个元素时重复计算 “左侧最大” 和 “右侧最小”，将时间复杂度从 O (n²) 优化到 O (n)（期末算法优化高频考点）。\n二、原代码拆解（正数场景下的问题） 1. 原代码核心逻辑（逐段解释） import java.util.Scanner; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); sc.nextLine(); String m = sc.nextLine().trim(); String[] fule = m.split(\u0026#34;\\\\s+\u0026#34;); // 分割输入字符串 // 转换为整数数组（正数场景下无负数） int[] love = new int[fule.length]; for (int i = 0; i \u0026lt; fule.length; i++) { love[i] = Integer.parseInt(fule[i]); } StringBuilder builder = new StringBuilder(); int count = 0; int lmax = -1; // ❌ 正数场景下初始值可简化为0，-1无意义 int rmin = findmin(love,0); // 实时计算右侧最小值，O(n²)超时 for (int i = 0; i \u0026lt; n; i++) { boolean gmzz = false; // ❌ 无意义判断：rmin是右侧最小值，和当前元素无关 if (rmin == love[i]) { rmin = findmin(love,i); } // 逻辑冗余：首尾判断可简化 if (i == 0) { gmzz = love[i] \u0026gt; lmax \u0026amp;\u0026amp; love[i] \u0026lt; rmin; if (love[i] \u0026gt; lmax) lmax = love[i]; } else if (i == n - 1) { gmzz = love[i] \u0026gt; lmax; if (love[i] \u0026gt; lmax) lmax = love[i]; } else { gmzz = love[i] \u0026gt; lmax \u0026amp;\u0026amp; love[i] \u0026lt; rmin; if (love[i] \u0026gt; lmax) lmax = love[i]; } // 收集结果 if (gmzz) { if (count \u0026gt; 0) builder.append(\u0026#34; \u0026#34;); builder.append(love[i]); count++; } } sc.close(); System.out.println(count); if (count \u0026gt; 0) System.out.println(builder.toString()); } // 实时计算i右侧最小值，每次O(n)，总时间O(n²) public static int findmin(int[] a,int i){ int n = a.length; int min = Integer.MAX_VALUE; for (int j = i + 1; j \u0026lt; n; j++) { if (a[j] \u0026lt; min) min = a[j]; } return min; } } 2. 原代码核心问题（正数场景下的优化点） 初始值冗余：正数场景下lmax初始为 - 1，可简化为 0（左侧无元素时最大值为 0，正数一定大于 0）； 时间复杂度高：findmin函数每次调用遍历 O (n)，n=1e5 时 O (n²) 直接超时； 逻辑冗余：首尾元素的判断分支可合并，无需单独写 3 个 if； 命名不规范：love/fule/gmzz等变量名无语义，复习时易混淆。 三、优化代码（分版本：正数专用 + 通用推广） 版本 1：正数专用版（简化初始值，适配题目默认场景） import java.util.Scanner; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); sc.nextLine(); // 输入处理：读取并转换为正整数数组 String inputStr = sc.nextLine().trim(); String[] strArr = inputStr.split(\u0026#34;\\\\s+\u0026#34;); int[] arr = new int[n]; for (int i = 0; i \u0026lt; n; i++) { arr[i] = Integer.parseInt(strArr[i]); // 题目保证输入为正数 } // 步骤1：预处理前缀最大值数组（leftMax[i] = 0~i-1的最大值，正数场景初始为0） int[] leftMax = new int[n]; leftMax[0] = 0; // 正数场景：左侧无元素，最大值为0（简化点） for (int i = 1; i \u0026lt; n; i++) { leftMax[i] = Math.max(leftMax[i-1], arr[i-1]); } // 步骤2：预处理后缀最小值数组（rightMin[i] = i+1~n-1的最小值） int[] rightMin = new int[n]; rightMin[n-1] = Integer.MAX_VALUE; // 最后一个元素右侧无元素，最小值为极大值 for (int i = n-2; i \u0026gt;= 0; i--) { rightMin[i] = Math.min(rightMin[i+1], arr[i+1]); } // 步骤3：遍历判断，收集结果（简化逻辑） StringBuilder resBuilder = new StringBuilder(); int count = 0; for (int i = 0; i \u0026lt; n; i++) { boolean isQualified = false; // 合并判断逻辑：仅首尾特殊处理，中间通用 if (i == 0) { isQualified = arr[i] \u0026lt; rightMin[i]; // 正数\u0026gt;0无需判断，仅需\u0026lt;右侧最小 } else if (i == n-1) { isQualified = arr[i] \u0026gt; leftMax[i]; } else { isQualified = arr[i] \u0026gt; leftMax[i] \u0026amp;\u0026amp; arr[i] \u0026lt; rightMin[i]; } // 收集结果 if (isQualified) { if (count \u0026gt; 0) resBuilder.append(\u0026#34; \u0026#34;); resBuilder.append(arr[i]); count++; } } // 输出结果（格式控制） System.out.println(count); if (count \u0026gt; 0) System.out.println(resBuilder.toString()); sc.close(); } } 版本 2：通用推广版（兼容负数，通用模板） import java.util.Scanner; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); sc.nextLine(); // 输入处理：兼容任意整数（正数/负数/0） String inputStr = sc.nextLine().trim(); String[] strArr = inputStr.split(\u0026#34;\\\\s+\u0026#34;); int[] arr = new int[n]; for (int i = 0; i \u0026lt; n; i++) { arr[i] = Integer.parseInt(strArr[i]); } // 步骤1：预处理前缀最大值数组（兼容负数，初始为MIN） int[] leftMax = new int[n]; leftMax[0] = Integer.MIN_VALUE; // 通用版：左侧无元素，最大值为整型最小值 for (int i = 1; i \u0026lt; n; i++) { leftMax[i] = Math.max(leftMax[i-1], arr[i-1]); } // 步骤2：预处理后缀最小值数组（通用版） int[] rightMin = new int[n]; rightMin[n-1] = Integer.MAX_VALUE; // 右侧无元素，最小值为整型最大值 for (int i = n-2; i \u0026gt;= 0; i--) { rightMin[i] = Math.min(rightMin[i+1], arr[i+1]); } // 步骤3：遍历判断（通用逻辑，无需简化） StringBuilder resBuilder = new StringBuilder(); int count = 0; for (int i = 0; i \u0026lt; n; i++) { boolean isQualified = false; if (i == 0) { isQualified = arr[i] \u0026gt; leftMax[i] \u0026amp;\u0026amp; arr[i] \u0026lt; rightMin[i]; } else if (i == n-1) { isQualified = arr[i] \u0026gt; leftMax[i]; } else { isQualified = arr[i] \u0026gt; leftMax[i] \u0026amp;\u0026amp; arr[i] \u0026lt; rightMin[i]; } if (isQualified) { if (count \u0026gt; 0) resBuilder.append(\u0026#34; \u0026#34;); resBuilder.append(arr[i]); count++; } } // 输出结果 System.out.println(count); if (count \u0026gt; 0) System.out.println(resBuilder.toString()); sc.close(); } } 四、核心步骤解析（算法思想 + 代码对应） 1. 预处理前缀最大值数组（leftMax） 算法思想：前缀数组—— 提前计算每个位置左侧的最大值，避免重复遍历；\n正数专用版：leftMax[0] = 0（左侧无元素，正数一定大于 0，无需判断arr[i] \u0026gt; leftMax[i]）； 通用推广版：leftMax[0] = Integer.MIN_VALUE（兼容负数，比如数组 …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766659536,"objectID":"38c81e18f9e005aaf462860841f0d346","permalink":"https://noctis-sikong.github.io/post/%E5%B7%A6%E4%BE%A7%E6%9C%80%E5%A4%A7-+-%E5%8F%B3%E4%BE%A7%E6%9C%80%E5%B0%8F%E5%85%83%E7%B4%A0%E7%AD%9B%E9%80%89/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E5%B7%A6%E4%BE%A7%E6%9C%80%E5%A4%A7-+-%E5%8F%B3%E4%BE%A7%E6%9C%80%E5%B0%8F%E5%85%83%E7%B4%A0%E7%AD%9B%E9%80%89/","section":"post","summary":"「左侧最大 + 右侧最小」元素筛选 一、题目核心分析与算法思想 1. 题目功能定义（默认输入为正数） 给定长度为 n 的正整数数组，筛选出满足以下条件的元素（「递增关键元素」）：\n第一个元素：大于左侧所有元素的最大值（左侧无元素，最大值为 0）且小于右侧所有元素的最小值；\n","tags":null,"title":"数组中「左侧最大 + 右侧最小」元素筛选","type":"post"},{"authors":null,"categories":null,"content":"最小生成树（MST）- Prim 算法 核心场景（详细版） 最小生成树（MST）适用于无向连通图，核心目标是：找到一组边，满足「连接所有顶点」且「边权和最小」，同时无环。\n典型应用：村村通公路（最低成本连接所有村庄）、网络布线（最低成本连接所有节点）；\n额外需求：若图不连通，无法生成 MST，需输出 - 1（表示需新增边）。\n分类一：算法思想（详细拆解，Prim 算法 —— 适合稠密图） Prim 算法基于「贪心策略」，核心是 “逐步扩展 MST，每次选连接 MST 和非 MST 的最小权值边”，步骤拆解如下：\n核心概念定义： MST 集合：已加入最小生成树的顶点集合； 距离数组 dist：dist [v] 表示「顶点 v 到 MST 集合的最小边权」（而非到起点的距离，区别于 Dijkstra）。 算法步骤： 步骤 1：初始化： 任选一个起点（如顶点 1），dist [start] = 0； 其余 dist [v] = INF（初始到 MST 无连接）； visited 数组全为 false（未加入 MST）。 步骤 2：循环 n 次（n = 顶点数）： 子步骤 1：找「未访问且 dist 最小」的顶点 u（该顶点是连接 MST 的最优选择）； 子步骤 2：若 u=-1（无可达顶点），说明图不连通，返回 - 1； 子步骤 3：将 u 加入 MST，累加 dist [u] 到总权值，标记 visited [u] = true； 子步骤 4：更新 u 的邻接顶点 v 的 dist：若 u→v 的边权 w \u0026lt;dist [v]，则 dist [v] = w（更新 v 到 MST 的最小边权）。 步骤 3：结果判断：若加入 MST 的顶点数≠n，说明图不连通，返回 - 1；否则返回总权值。 通用精简代码 import java.util.*; public class Prim { public static final int INF = Integer.MAX_VALUE; // 通用Prim：返回MST总权值，不连通返回-1 // 参数：n=顶点数（1~n），adj=邻接表（adj[u]存储{v, w}） public static int prim(int n, List\u0026lt;List\u0026lt;int[]\u0026gt;\u0026gt; adj) { boolean[] visited = new boolean[n + 1]; // 1基 int[] dist = new int[n + 1]; Arrays.fill(dist, INF); dist[1] = 0; // 起点选1（任选，不影响结果） int total = 0; // MST总权值 int count = 0; // 加入MST的顶点数 for (int i = 0; i \u0026lt; n; i++) { // 步骤1：找未访问的dist最小顶点u int u = -1; int minDis = INF; for (int j = 1; j \u0026lt;= n; j++) { if (!visited[j] \u0026amp;\u0026amp; dist[j] \u0026lt; minDis) { minDis = dist[j]; u = j; } } if (u == -1) return -1; // 不连通 // 步骤2：加入MST，累加权值 visited[u] = true; total += minDis; count++; // 步骤3：更新邻接顶点的dist（到MST的最小边权） for (int[] edge : adj.get(u)) { int v = edge[0]; int w = edge[1]; if (!visited[v] \u0026amp;\u0026amp; w \u0026lt; dist[v]) { dist[v] = w; } } } return count == n ? total : -1; } // 复用入口（适配\u0026#34;公路村村通\u0026#34;\u0026#34;畅通工程2\u0026#34;） public static void main(String[] args) { Scanner sc = new Scanner(System.in); while (sc.hasNext()) { int n = sc.nextInt(); // 顶点数 if (n == 0) break; // 终止条件 int m = n == 1 ? 0 : sc.nextInt(); // 边数（n=1时无需边） // 初始化邻接表（1基） List\u0026lt;List\u0026lt;int[]\u0026gt;\u0026gt; adj = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt;= n; i++) adj.add(new ArrayList\u0026lt;\u0026gt;()); // 处理边输入（适配不同题目格式） int edgeCount = n == 1 ? 0 : (n*(n-1)/2); // 畅通工程2的边数 edgeCount = m == 0 ? edgeCount : m; // 公路村村通用m for (int i = 0; i \u0026lt; edgeCount; i++) { int u = sc.nextInt(); int v = sc.nextInt(); int w = sc.nextInt(); // 无向图：双向添加边 adj.get(u).add(new int[]{v, w}); adj.get(v).add(new int[]{u, w}); } // 执行Prim int res = prim(n, adj); System.out.println(res == -1 ? -1 : res); } sc.close(); } } 核心考点（详细解释） Prim vs Dijkstra 的区别： Prim 的 dist [v]：顶点 v 到 MST 的最小边权； Dijkstra 的 dist [v]：顶点 v 到起点的最短路径长度； 两者贪心策略相同（选最小 dist 的顶点），但 dist 的含义完全不同； 起点选择：任选一个顶点作为起点（如 1），最终 MST 的总权值相同； 稠密图适配性：Prim 算法（基础版 O (n²)）适合稠密图（边数多），Kruskal 算法适合稀疏图； 连通性判断：count（加入 MST 的顶点数）==n → 连通，否则不连通。 易错点（详细说明错误原因 + 正确做法） 易错点 错误原因 正确做法 混淆 Prim 和 Dijkstra dist 数组含义理解错误 牢记 Prim 的 dist 是 “到 MST 的最小边权” 无向图未双向加边 邻接表漏边，导致 MST 无法生成 必须同时添加 u→v 和 v→u 的边 顶点编号未适配 1 基 数组越界（题目顶点从 1 开始） 数组开到 n+1，遍历从 1 开始 起点 dist 未设 0 第一个顶点无法被选中 强制设置 dist [start] = 0（如 dist [1]=0） 总结（辅助记忆） Prim 算法核心口诀：「选最小边权点→加入 MST→更新邻接边权→统计顶点数判连通」；\n核心区别：dist 数组是 “到 MST 的最小边权”（而非到起点的距离）；\n核心适用：无向稠密图、求最小权值连通边集。\n分类二：最小生成树（MST）- Kruskal 算法 核心场景（详细版） 最小生成树（MST）适用于无向连通图，核心目标与 Prim 算法一致：找到一组边，满足「连接所有顶点」且「边权和最小」，同时无环。\n典型应用：与 Prim 算法相同（如村村通公路、网络布线），但更适用于稀疏图（边数少的场景）； 额外需求：若图不连通，无法生成 MST，需输出 -1（表示需新增边）。 算法思想（详细拆解，Kruskal 算法 —— 适合稀疏图） Kruskal 算法同样基于「贪心策略」，核心是 “从边的角度选最小权值边，避免形成环”，步骤拆解如下：\n核心概念定义： 边集排序：所有边按权值从小到大排序； 并查集（Union-Find）：用于高效判断「添加一条边是否会形成环」（检测两顶点是否已在同一连通分量）。 算法步骤： 步骤 1：初始化： 将所有边按权值升序排序； 初始化并查集（每个顶点独立成树）； 定义变量 total 记录 MST 总权值，count 记录加入 MST 的边数（最终需为 n-1，n 为顶点数）。 步骤 2：遍历排序后的边： 子步骤 1：取当前权值最小的边（u, v, w）； 子步骤 2：用并查集判断 u 和 v 是否在同一连通分量： 若不在：将边加入 MST，total += w，count += 1，合并 u 和 v 所在的集合； 若在：跳过（避免形成环）。 步骤 3：结果判断：若 count == n-1（所有顶点连通），返回 total；否则返回 -1（图不连通）。 通用精简代码 import java.util.*; public class Kruskal { // 并查集实现（用于检测环和合并集合） static class UnionFind { int[] parent; int[] rank; // 按秩合并优化 public UnionFind(int n) { parent = new int[n + 1]; // 1基 rank = new int[n + 1]; for (int i = 1; i \u0026lt;= n; i++) { parent[i] = i; // 自身为父节点 rank[i] = 1; // 初始秩为1 } } // 查找根节点（路径压缩优化） public int find(int x) { if (parent[x] != x) { parent[x] = find(parent[x]); // 路径压缩 } return parent[x]; } // 合并两个集合（按秩合并） public boolean union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX == rootY) return false; // 已在同一集合（会形成环） // 秩小的树合并到秩大的树 if (rank[rootX] \u0026lt; rank[rootY]) { parent[rootX] = rootY; } else if (rank[rootX] \u0026gt; rank[rootY]) { parent[rootY] = rootX; } else { parent[rootY] = rootX; rank[rootX]++; } return true; } } // 通用Kruskal：返回MST总权值，不连通返回-1 // 参数：n=顶点数（1~n），edges=边列表（每个元素为{u, v, w}） public static int kruskal(int n, List\u0026lt;int[]\u0026gt; edges) { // 步骤1：边按权值升序排序 Collections.sort(edges, (a, b) -\u0026gt; a[2] - b[2]); UnionFind uf = new UnionFind(n); int total = 0; // MST总权值 int count = 0; // 加入MST的边数（需达到n-1） // 步骤2：遍历所有边 for (int[] edge : edges) { int u = edge[0]; int v = edge[1]; int w = edge[2]; // 若u和v不在同一集合，加入边并合并 if (uf.union(u, v)) { total += w; count++; // 已收集足够边（n-1条），提前退出 if (count == n - 1) break; } } // 步骤3：判断是否连通 return count == n - 1 ? total : -1; } // 复用入口（适配稀疏图场景） public static void …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766662225,"objectID":"a2163db570b9313e5d1e054cf05ed68c","permalink":"https://noctis-sikong.github.io/post/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91mst--prim-%E7%AE%97%E6%B3%95/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91mst--prim-%E7%AE%97%E6%B3%95/","section":"post","summary":"最小生成树（MST）- Prim 算法 核心场景（详细版） 最小生成树（MST）适用于无向连通图，核心目标是：找到一组边，满足「连接所有顶点」且「边权和最小」，同时无环。\n典型应用：村村通公路（最低成本连接所有村庄）、网络布线（最低成本连接所有节点）；\n额外需求：若图不连通，无法生成 MST，需输出 - 1（表示需新增边）。\n","tags":null,"title":"最小生成树（MST）","type":"post"},{"authors":null,"categories":null,"content":"最短路径算法 包含Floyd-Warshall（多源最短路径）Dijkstra（单源最短路径）两种算法\n子分类 1：Floyd-Warshall（弗洛伊德，多源最短路径） 核心场景（详细版） Floyd 算法是多源最短路径的经典实现，可一次性求出「任意两个顶点之间」的最短路径，适合以下场景：\n顶点数少（n≤100）：时间复杂度 O (n³)，n\u0026gt;100 时会超时； 无负权环（允许负权边）：若存在负权环，最短路径无意义； 需批量查询：如同时求起点 0 到所有点、点 P 到点 Q 的最短路径（如 “最短路径”“畅通工程 3” 变种）。 算法思想（详细拆解） Floyd 算法基于「动态规划」思想，核心是 “松弛操作”，步骤拆解如下：\n核心概念定义： 距离矩阵 dist：dist [i][j] 表示「从顶点 i 到顶点 j 的当前最短路径长度」； 松弛操作（Relaxation）：对于路径 i→j，若存在中间点 k，使得 i→k→j 的路径比 i→j 更短，则更新 dist [i][j] = dist [i][k] + dist [k][j]。 算法步骤： 步骤 1：初始化距离矩阵： 若 i==j，dist [i][j] = 0（自身到自身距离为 0）； 若 i 和 j 有直达边，dist [i][j] = 边权； 若无直达边，dist [i][j] = INF（无穷大，需选合适值，避免溢出）。 步骤 2：三重循环松弛操作（核心）： 外层循环：枚举中间点 k（所有可能的中转点）； 中层循环：枚举起点 i； 内层循环：枚举终点 j； 松弛判断：若 dist [i][k] \u0026lt; INF 且 dist [k][j] \u0026lt; INF（i 到 k、k 到 j 均可达），且 dist [i][k]+dist [k][j] \u0026lt; dist [i][j]，则更新 dist [i][j]。 步骤 3：结果使用：dist [i][j] 即为 i 到 j 的最短路径长度，若 dist [i][j] == INF 则不可达。 通用精简代码（注释清晰，脱离题目限制） import java.util.*; public class Floyd { // 无穷大取值：10000（需大于题目中最大可能路径和，避免溢出） public static final int INF = 10000; // 通用Floyd：返回任意两点最短路径矩阵 // 参数：n=顶点数，cost=原始邻接矩阵（cost[i][j]为i到j的直达边权，无则为INF） public static int[][] floyd(int n, int[][] cost) { int[][] dist = new int[n][n]; // 步骤1：初始化距离矩阵 for (int i = 0; i \u0026lt; n; i++) { System.arraycopy(cost[i], 0, dist[i], 0, n); dist[i][i] = 0; // 自身到自身距离强制为0 } // 步骤2：三重循环松弛（k=中间点，i=起点，j=终点） for (int k = 0; k \u0026lt; n; k++) { for (int i = 0; i \u0026lt; n; i++) { for (int j = 0; j \u0026lt; n; j++) { // 必须判断i→k、k→j可达，避免INF+INF溢出 if (dist[i][k] \u0026lt; INF \u0026amp;\u0026amp; dist[k][j] \u0026lt; INF) { dist[i][j] = Math.min(dist[i][j], dist[i][k] + dist[k][j]); } } } } return dist; } // 复用入口（适配各类多源最短路径题） public static void main(String[] args) { Scanner sc = new Scanner(System.in); while (sc.hasNext()) { int n = sc.nextInt(); // 顶点数 int m = sc.nextInt(); // 查询数（按需） sc.nextLine(); // 初始化原始邻接矩阵 int[][] cost = new int[n][n]; for (int i = 0; i \u0026lt; n; i++) { Arrays.fill(cost[i], INF); String[] parts = sc.nextLine().trim().split(\u0026#34;,\u0026#34;); for (int j = 0; j \u0026lt; n; j++) { cost[i][j] = Integer.parseInt(parts[j].trim()); } } // 执行Floyd int[][] dist = floyd(n, cost); // 示例1：输出起点0到所有可达点的排序结果（按距离升序、编号升序） List\u0026lt;Integer\u0026gt; nodes = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { if (dist[0][i] \u0026lt; INF) nodes.add(i); } Collections.sort(nodes, (a, b) -\u0026gt; dist[0][a] != dist[0][b] ? dist[0][a]-dist[0][b] : a-b); for (int i = 0; i \u0026lt; nodes.size(); i++) { if (i \u0026gt; 0) System.out.print(\u0026#34; \u0026lt;= \u0026#34;); System.out.print(nodes.get(i)); } System.out.println(); // 示例2：处理点对查询（P→Q的最短路径） for (int i = 0; i \u0026lt; m; i++) { int p = sc.nextInt(); int q = sc.nextInt(); System.out.println(dist[p][q] \u0026gt;= INF ? -1 : dist[p][q]); } } sc.close(); } } 核心考点（详细解释） 三重循环顺序：必须先枚举中间点 k，再枚举 i 和 j—— 因为 Floyd 的核心是 “通过 k 松弛 i→j”，若 k 在最内层，无法利用已更新的 dist [i][k] 和 dist [k][j]； 无穷大取值原则： 不能用 Integer.MAX_VALUE：因为 INF+INF 会溢出为负数，导致松弛判断错误； 需选 “略大于题目中最大可能路径和” 的值（如题目中最大路径和为 9999，则选 10000）； 负权边处理：允许负权边，但不允许负权环（负权环会导致路径长度无限减小，最短路径无意义）； 重边处理：若 i 和 j 之间有多个直达边，初始化时需取权值最小的边（如 cost [i][j] = min (原 cost [i][j], 新边权)）。 易错点（详细说明错误原因 + 正确做法） 易错点 错误原因 正确做法 无穷大取值错误 用 Integer.MAX_VALUE 导致溢出 选 10000/0x3f3f3f3f 等安全值 三重循环顺序错误 k 在最内层，无法正确松弛 严格按 k→i→j 顺序循环 松弛前未判可达 INF+INF 溢出，更新错误值 先判断 dist [i][k] \u0026lt; INF \u0026amp;\u0026amp; dist [k][j] \u0026lt; INF 初始化未设 dist [i][i]=0 自身到自身距离为 INF，导致错误 强制设置 dist [i][i] = 0 子分类 2.2：Dijkstra（迪杰斯特拉，单源最短路径） 核心场景（详细版） Dijkstra 算法是单源最短路径的最优实现（边权非负），核心目标是求「单个起点到所有其他顶点」的最短路径，适合以下场景：\n边权非负：若有负权边，需改用 Bellman-Ford 或 SPFA； 顶点数中等（n≤200）：基础版 O (n²)，堆优化版 O (m log n)（适合 n\u0026gt;200）； 单次起点查询：如 “从起点 S 到终点 T 的最短路径”（如 “畅通工程 3”）。 算法思想（详细拆解） Dijkstra 算法基于「贪心策略」，核心是 “每次选距离起点最近的未访问顶点，松弛其邻接顶点”，步骤拆解如下：\n核心概念定义： 距离数组 dist：dist [v] 表示「从起点到顶点 v 的当前最短路径长度」； 访问标记数组 visited：标记顶点是否已确定最短路径（一旦标记，不再更新）。 算法步骤： 步骤 1：初始化： dist [start] = 0（起点到自身距离为 0）； 其余 dist [v] = INF（初始不可达）； visited 数组全为 false（所有顶点未确定最短路径）。 步骤 2：循环 n 次（n = 顶点数）： 子步骤 1：找「未访问且 dist 最小」的顶点 u（贪心选择，该顶点的最短路径已确定）； 子步骤 2：标记 u 为已访问（visited [u] = true）； 子步骤 3：松弛 u 的所有邻接顶点 v：若 dist [u] + w (u,v) \u0026lt; dist [v]（w 为 u→v 的边权），则更新 dist [v] = dist [u] + w (u,v)。 步骤 3：结果使用：dist [end] 即为起点到终点的最短路径长度，若 dist [end] == INF 则不可达。 通用精简代码（邻接表版，更高效，注释清晰） java\n运行\nimport java.util.*; public class Dijkstra { // 安全无穷大：0x3f3f3f3f（十进制1061109567，相加不溢出） public static final int INF = 0x3f3f3f3f; // 通用Dijkstra：返回起点到所有顶点的最短路径数组 // 参数：n=顶点数，adj=邻接表（adj[u]存储{v, w}，表示u→v的边权为w），start=起点 public static int[] dijkstra(int n, List\u0026lt;List\u0026lt;int[]\u0026gt;\u0026gt; adj, int start) { int[] dist = new int[n]; boolean[] visited = new boolean[n]; Arrays.fill(dist, INF); dist[start] = 0; for (int i = 0; i \u0026lt; n; i++) { // 步骤1：找未访问的dist最小顶点u int u = -1; int minDis = INF; for (int j = 0; j \u0026lt; n; j++) { if (!visited[j] \u0026amp;\u0026amp; dist[j] \u0026lt; minDis) { minDis = dist[j]; u = j; } } if (u == -1) break; // 无可达顶点，提前结束 // 步骤2：标记已访问，松弛邻接顶点 visited[u] = true; for (int[] edge : adj.get(u)) { int v = edge[0]; int w = edge[1]; // 松弛操作：仅更新未访问顶点 if (!visited[v] \u0026amp;\u0026amp; dist[u] + w \u0026lt; dist[v]) { dist[v] = dist[u] + w; } } } return dist; } // 复用入口（适配\u0026#34;畅通工程3\u0026#34;等单源最短路径题） public static void main(String[] args) { Scanner sc = new Scanner(System.in); while (sc.hasNext()) { int n = sc.nextInt(); // 顶点数（0~n-1） int m = sc.nextInt(); // 边数 // 初始化邻接表：adj[u] = {{v1, w1}, …","date":1766662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766660536,"objectID":"206b33caf9d4128943ec824cc32224a6","permalink":"https://noctis-sikong.github.io/post/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/","publishdate":"2025-12-25T19:30:10+08:00","relpermalink":"/post/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/","section":"post","summary":"最短路径算法 包含Floyd-Warshall（多源最短路径）Dijkstra（单源最短路径）两种算法\n子分类 1：Floyd-Warshall（弗洛伊德，多源最短路径） 核心场景（详细版） Floyd 算法是多源最短路径的经典实现，可一次性求出「任意两个顶点之间」的最短路径，适合以下场景：\n顶点数少（n≤100）：时间复杂度 O (n³)，n\u003e100 时会超时； 无负权环（允许负权边）：若存在负权环，最短路径无意义； 需批量查询：如同时求起点 0 到所有点、点 P 到点 Q 的最短路径（如 “最短路径”“畅通工程 3” 变种）。 算法思想（详细拆解） Floyd 算法基于「动态规划」思想，核心是 “松弛操作”，步骤拆解如下：\n","tags":null,"title":"最短路径","type":"post"},{"authors":null,"categories":null,"content":"深度学习：卷积神经网络中的卷积核核心知识总结 卷积核是 CNN 实现图像特征提取的核心组件，其设计与运算直接决定网络性能。本文将浓缩卷积核的本质、特性、运算原理及 1x1 特殊卷积核的核心作用。\n一、卷积核的本质与核心作用 卷积核（又称滤波器）是图像处理中用于提取特征的核心工具，其本质是对输入图像的局部区域（感受野）进行像素加权平均运算，权值由预设函数定义。在卷积神经网络（CNN）中，卷积核承担着 “前排特征提取” 的关键角色，CNN 的核心逻辑就是通过卷积核不断提取图像特征、进行特征选择，最终实现分类任务，本质上是计算图像局部与卷积核的互相关函数。\n二、卷积核的关键特性 特征提取的特异性： 不同卷积核可提取图像的不同特征（如边缘、纹理、轮廓等）； 即使目标特征相同，不同规格的卷积核（如 3x3 与 5x5）提取效果也存在差异（例：5x5 锐化卷积核的效果比 3x3 更细腻）。 尺寸规格： 常用尺寸为 1x1、3x3、5x5，通常采用奇数 × 奇数设计； 卷积核尺寸直接影响特征提取的粒度，小尺寸核侧重局部细节，大尺寸核侧重更广泛的特征关联。 维度匹配规则： 卷积核的输入通道数（in depth）由输入图像的通道数决定（如 RGB 三通道图像需对应 3 通道卷积核）； 每个卷积核会将所有输入通道压缩为单个输出通道，输出特征图（feature map）的数量等于卷积核的个数。 三、卷积运算的核心原理 1. 运算过程 以输入 224x224x3（RGB 三通道）、输出 32 位深度、卷积核尺寸 5x5 为例：\n需配置 32 个 5x5x3 规格的卷积核（最后一维与输入通道数匹配）； 每个卷积核的 3 层（5x5）分别与输入图像的对应通道卷积； 将 3 次卷积结果算术求和，得到 1 张深度为 1 的 feature map； 32 个卷积核分别运算后，最终输出 32 张不同的 feature map。 2. 核心公式 $$a_{i,j} = f\\left( \\sum_{d=0}^{D-1} \\sum_{m=0}^{F-1} \\sum_{n=0}^{F-1} w_{d,m,n} \\cdot x_{d,i+m,j+n} + w_b \\right)$$\n符号说明：D 为输入深度，F 为卷积核尺寸，w**d,m,n为卷积核第 d 层第 m 行第 n 列权重，x**d,i+j,j+n为图像第 d 层第 i 行第 j 列像素，w**b为偏置项，f 为激活函数。 3. 输入输出尺寸计算 输入矩阵格式：样本数 × 图像高度 × 图像宽度 × 通道数；\n输出矩阵格式：样本数 × 输出高度 × 输出宽度 × 输出通道数（= 卷积核个数）；\n尺寸计算公式（忽略偏置项）：\n$$ \\begin{cases} height_{out} = \\frac{height_{in} - height_{kernel} + 2 \\times padding}{stride} + 1 \\ width_{out} = \\frac{width_{in} - width_{kernel} + 2 \\times padding}{stride} + 1 \\end{cases} $$\n关键参数：stride（步长）为卷积核滑动间隔，padding（填充）为输入图像边缘补充像素数。\n四、特殊卷积核：1x1 卷积核 1. 本质定位 1x1 卷积核又称 “网中网（Network in Network）\u0026#34;，可看作一种跨通道的池化操作或简化的全连接层，核心特点是不改变输出特征图的宽度和高度，仅调整通道数。\n2. 核心作用 降维 / 升维：当卷积核个数小于输入通道数时实现降维（如 6x6x32 输入经 1x1x32 卷积核输出 6x6x1），大于输入通道数时实现升维，本质是调整 height×width×channels 中通道维度的大小； 增加非线性：在保持特征图分辨率不变的前提下，通过后接的非线性激活函数（如 ReLU）大幅提升网络的非线性表达能力，支持构建更深的网络； 跨通道信息交互：实现不同通道间的线性组合，例如将 64 通道通过 1x1 卷积核线性组合为 28 通道，完成通道间的信息融合（仅在通道维度运算，宽高维度共享权值滑动窗口）。 五、补充：池化与卷积的关联 池化（pooling）是卷积后的特征聚合操作，用于获取全局特征，与卷积形成互补：\n作用：对单个卷积通道的局部特征进行全局聚合，实现特征降维或升维，增强特征的全局性； 与 1x1 卷积的关联：1x1 卷积可看作跨通道的池化操作，二者均具备维度调整功能。 原文链接：https://blog.csdn.net/Vermont_/article/details/108690251\n本文为原文核心内容归纳总结，仅用于个人学习存档，无任何商业用途，版权归原作者所有。\n","date":1765546510,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1766114452,"objectID":"b08440e1de1b43b395088562bb63809c","permalink":"https://noctis-sikong.github.io/post/%E5%8D%B7%E7%A7%AF%E6%A0%B8/","publishdate":"2025-12-12T21:35:10+08:00","relpermalink":"/post/%E5%8D%B7%E7%A7%AF%E6%A0%B8/","section":"post","summary":"深度学习：卷积神经网络中的卷积核核心知识总结 卷积核是 CNN 实现图像特征提取的核心组件，其设计与运算直接决定网络性能。本文将浓缩卷积核的本质、特性、运算原理及 1x1 特殊卷积核的核心作用。\n","tags":null,"title":"卷积核","type":"post"},{"authors":null,"categories":null,"content":"核心理论学习（聚焦原文+基础补充）：深度拆解+学术衔接 学术课题的理论学习，核心是“先懂原文创新逻辑，再补基础理论短板”——既要能说清Crack-Segmenter每个模块“为什么这么设计”“解决了什么核心问题”，也要能衔接深度学习、图像分割的通用理论，为论文的“相关工作”“方法原理”章节奠定基础。以下是分模块、可落地的详细学习内容：\n第一部分：Crack-Segmenter原文核心创新模块（逐模块拆解，附代码链接） 原文的核心价值是“用全自监督方式解决裂缝分割的3大痛点”：① 细裂缝与宽裂缝难以兼顾；② 裂缝线性结构易被破坏；③ 无监督信号导致训练不稳定。对应的4个创新模块，需按“设计动机→核心原理→实现逻辑→学术价值”四层拆解，所有核心代码均来自原文开源仓库：\n原文GitHub开源仓库（核心代码获取）：https://github.com/Blessing988/Crack-Segmenter（含完整模型代码、训练脚本、配置文件，复现必备）\n模块1：SAE（尺度自适应嵌入器）—— 解决“多尺度裂缝捕捉”问题 1. 设计动机（为什么需要这个模块？） 裂缝分割的核心难点之一：裂缝尺度差异极大（从发丝细的微裂缝到毫米级宽裂缝）。传统分割模型的问题：\n小卷积核（1×1）只能捕捉细裂缝，但会遗漏宽裂缝的全局特征； 大卷积核（7×7）能捕捉宽裂缝，但会模糊细裂缝的细节； 普通多尺度特征融合（如简单拼接）会导致特征冗余，背景干扰严重。 原文提出SAE，目标是“用轻量结构同时捕捉3类尺度特征，且不增加过多计算量”。\n2. 核心原理（怎么实现的？） SAE的本质是“多分支卷积+特征对齐”，结构如下（简化版，对应原文图2）：\n输入特征图（H×W×C） → 3个并行卷积分支 → BatchNorm归一化 → 特征拼接 → 输出多尺度嵌入特征（H×W×3C）\n每个分支的作用：\n分支类型 卷积核/步长 捕捉特征尺度 对应裂缝场景 细尺度分支 1×1 卷积 局部细粒度特征 手机屏幕微裂缝、发丝裂缝 中尺度分支 3×3 卷积 中等尺度连续特征 普通宽度裂缝（1-2mm） 粗尺度分支 3×3 卷积+步长2 + 上采样 全局宽尺度特征 宽裂缝、断裂型长裂缝 关键设计细节：\n用1×1卷积降维：每个分支输出通道数为C/3（原文C=64），避免拼接后特征维度爆炸； 上采样对齐：粗尺度分支步长2会缩小特征图，用双线性插值上采样到原尺寸，保证3个分支特征图大小一致，才能拼接； BatchNorm归一化：每个分支后加BN，稳定训练，避免梯度消失。 3. 实现逻辑（对应GitHub代码） 开源代码中SAE的核心实现（简化自仓库 models/crack_segmenter.py 文件）：\nclass SAE(nn.Module): def __init__(self, in_channels=64, out_channels=64): super().__init__() mid_channels = out_channels // 3 # 每个分支输出通道数 # 3个尺度分支 self.branch1 = nn.Sequential(nn.Conv2d(in_channels, mid_channels, 1), nn.BatchNorm2d(mid_channels)) # 细尺度 self.branch2 = nn.Sequential(nn.Conv2d(in_channels, mid_channels, 3, padding=1), nn.BatchNorm2d(mid_channels)) # 中尺度 self.branch3 = nn.Sequential( nn.Conv2d(in_channels, mid_channels, 3, stride=2, padding=1), # 步长2缩小 nn.BatchNorm2d(mid_channels), nn.Upsample(scale_factor=2, mode=\u0026#39;bilinear\u0026#39;, align_corners=True) # 上采样对齐 ) # 粗尺度 def forward(self, x): # 并行计算3个分支 x1 = self.branch1(x) x2 = self.branch2(x) x3 = self.branch3(x) return torch.cat([x1, x2, x3], dim=1) # 拼接特征（通道维度） 4. 学术价值（论文中怎么写？） - 轻量性：仅用3个简单卷积分支，参数增量\u0026lt;10%，相比传统多尺度模块（如FPN）计算量减少40%；\n- 针对性：专门适配裂缝“多尺度分布”的特点，比通用多尺度模块（如ResNet的多尺度特征）更聚焦裂缝特征；\n- 可迁移性：对手机屏幕、玻璃等场景的多尺度裂缝同样适用，为后续场景适配埋下伏笔。\n模块2：DAT（方向注意力Transformer）—— 解决“裂缝线性结构保持”问题 1. 设计动机（为什么需要这个模块？） 裂缝的本质是“线性连续结构”（比如手机屏幕裂缝从边角延伸，呈直线/曲线连续分布）。传统Transformer/注意力机制的问题：\n全局注意力：计算每个像素与所有像素的关联，会破坏裂缝的线性连续性（比如把裂缝和背景像素关联）； 普通局部注意力：只关注固定窗口内的像素，无法捕捉长距离的线性关联（比如长裂缝两端的像素）； 无方向感知：无法区分“横向/纵向/斜向”裂缝，导致分割结果碎片化（裂缝断成多段）。 原文提出DAT，目标是“强化裂缝的方向特异性和线性连续性，让模型只关注同方向的裂缝像素”。\n2. 核心原理（怎么实现的？） DAT的核心是“定向卷积生成方向特征+方向注意力权重计算”，步骤如下（对应原文图3）：\n方向特征提取：用4个定向卷积核（0°、45°、90°、135°）对输入特征图卷积，生成4个方向的特征图（每个方向对应一种裂缝走向）； 生成Q/K/V：Q（查询）：方向特征图经过1×1卷积降维得到；K（键）：和Q同源，确保方向一致性；V（值）：原始输入特征图经过1×1卷积，保留原始特征信息； 方向注意力权重计算：计算Q和K的相似度（点积注意力），得到方向注意力图（每个像素的权重表示“该像素与同方向裂缝像素的关联程度”）；用Softmax归一化权重，确保权重和为1； 特征加权融合：注意力权重与V相乘，得到“方向增强后的特征图”——同方向的裂缝像素被强化，背景和异方向像素被抑制。 3. 实现逻辑（对应GitHub代码） 开源代码中DAT的核心实现（简化自仓库 models/crack_segmenter.py 文件）：\nclass DAT(nn.Module): def __init__(self, channels=64): super().__init__() # 4个方向的定向卷积核（0°,45°,90°,135°） self.directional_conv = nn.Conv2d(channels, channels*4, kernel_size=3, padding=1, groups=channels) self.q_conv = nn.Conv2d(channels*4, channels*4, 1) self.k_conv = nn.Conv2d(channels*4, channels*4, 1) self.v_conv = nn.Conv2d(channels, channels*4, 1) self.residual = nn.Conv2d(channels*4, channels, 1) # 残差连接降维 def forward(self, x): residual = x # 残差保存 # 1. 方向特征提取 dir_feat = self.directional_conv(x) # 输出：H×W×(64×4) # 2. 生成Q/K/V q = self.q_conv(dir_feat) k = self.k_conv(dir_feat) v = self.v_conv(x) # 3. 方向注意力计算（点积注意力） b, c, h, w = q.shape q = q.view(b, c, h*w).permute(0, 2, 1) # 转置为 (b, h*w, c) k = k.view(b, c, h*w) # (b, c, h*w) attn_weight = torch.bmm(q, k) # 批量矩阵乘法：(b, h*w, h*w) attn_weight = F.softmax(attn_weight, dim=-1) # 4. 特征加权融合 v = v.view(b, c, h*w) # (b, c, h*w) attn_feat = torch.bmm(v, attn_weight.permute(0, 2, 1)) # (b, c, h*w) attn_feat = attn_feat.view(b, c, h, w) # 5. 残差连接 out = self.residual(attn_feat) + residual return out 4. 学术价值（论文中怎么写？） - 针对性：首次将“方向注意力”引入裂缝分割，解决传统注意力机制“忽视线性结构”的痛点；\n- 高效性：用定向卷积替代Transformer的全局注意力，计算量减少60%，同时保持长距离线性关联捕捉能力；\n- 效果验证：后续消融实验中，移除DAT模块后mIoU下降15%-20%，证明其对裂缝连续性的关键作用。\n模块3：AGF（注意力引导融合模块）—— 解决“多尺度特征冗余”问题 1. 设计动机（为什么需要这个模块？） SAE输出多尺度特征后，直接拼接会存在两个问题：① 特征冗余：不同尺度特征存在重叠信息（比如细裂缝和中裂缝的边缘特征），增加模型计算负担；② 背景干扰：多尺度特征中包含大量背景噪声（如屏幕反光、路面纹理），会影响裂缝分割精度。\n原文提出AGF，目标是“智能筛选多尺度特征中的有效信息（裂缝相关），抑制冗余和背景干扰”。\n2. 核心原理（怎么实现的？） AGF的本质是“特征注意力权重计算+加权融合”，步骤如下：① 多尺度特征拼接；② 全局注意力权重计算；③ 特征加权筛选；④ 降维输出。关键设计细节：全局平均池化（捕捉每个通道的全局信息）、MLP非线性变换（轻量学习特征重要性）、逐通道加权（精准筛选有效通道）。\n3. 实现逻辑（对应GitHub代码） 开源代码中AGF的核心实现（简化自仓库models/crack_segmenter.py 文件）：\nclass AGF(nn.Module): def __init__(self, in_channels=192, out_channels=64): super().__init__() self.global_pool = nn.AdaptiveAvgPool2d(1) # 全局平均池化 self.mlp = nn.Sequential( nn.Conv2d(in_channels, in_channels//4, 1), # 降维 nn.ReLU(), nn.Conv2d(in_channels//4, in_channels, 1) # 升维 ) self.conv = nn.Conv2d(in_channels, out_channels, 1) # 最终降维 def forward(self, x): # x：SAE输出的拼接特征（H×W×192，即3×64） b, c, h, w = x.shape # 1. 全局注意力权重计算 global_feat = self.global_pool(x) # (b, 192, 1, 1) attn_weight = self.mlp(global_feat) # (b, 192, 1, 1) attn_weight = torch.sigmoid(attn_weight) …","date":1765539010,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1765545951,"objectID":"b19854455cdbb890a559a82a9ec1068f","permalink":"https://noctis-sikong.github.io/post/crack-segmenter%E6%A0%B8%E5%BF%83%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/","publishdate":"2025-12-12T19:30:10+08:00","relpermalink":"/post/crack-segmenter%E6%A0%B8%E5%BF%83%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/","section":"post","summary":"核心理论学习（聚焦原文+基础补充）：深度拆解+学术衔接 学术课题的理论学习，核心是“先懂原文创新逻辑，再补基础理论短板”——既要能说清Crack-Segmenter每个模块“为什么这么设计”“解决了什么核心问题”，也要能衔接深度学习、图像分割的通用理论，为论文的“相关工作”“方法原理”章节奠定基础。以下是分模块、可落地的详细学习内容：\n","tags":null,"title":"Crack-Segmenter核心理论学习","type":"post"},{"authors":null,"categories":null,"content":"村村通问题的本质 本题要求计算使所有村落连通的最低公路建设成本，本质是求解最小生成树（MST） 问题。最小生成树的核心是在无向图中选择 N-1 条边（N 为节点数），使得所有节点连通且总权重最小。常用的算法有 Kruskal（克鲁斯卡尔）和 Prim（普里姆），这里选择 Kruskal 算法，因为其通过排序边 + 并查集（Union-Find）的方式实现，逻辑清晰且适配本题数据规模（N≤1000，M≤3N）。\nKruskal 算法思路 Kruskal（克鲁斯卡尔）算法是求解无向图最小生成树（MST） 的经典贪心算法，核心逻辑是：按边的权重从小到大依次选边，且保证选的边不形成环，直到选够「节点数 - 1」条边（生成树的边数固定为节点数 - 1）。\n该算法的关键是「贪心选边」+「并查集（Union-Find）判环 / 合并集合」，专门适配 “村村通” 这类求最小连通成本的问题，以下是分步骤的详细思路：\n步骤拆解（结合 “村村通” 场景） 假设场景：有 N 个村落（节点），M 条可选道路（边），每条道路有建设成本（边的权重），目标是用最低成本让所有村落连通。\n步骤 1：预处理 —— 边按权重升序排序 将所有候选道路（边）按照建设成本（权重）从小到大排序。\n贪心逻辑：优先选成本最低的道路，是实现 “最小总成本” 的核心。 例如样例中，先排序出权重 1 的边（3-5、3-6），再是权重 2 的边（2-5、1-6），依此类推。 步骤 2：初始化并查集 并查集是一种高效管理 “集合归属” 的数据结构，用于快速判断「两个村落是否已连通」（避免选边形成环）、「合并两个不连通的村落集合」。\n初始化：每个村落独立为一个集合（即每个节点的父节点指向自己）。 例如样例中，初始时村落 1、2、3、4、5、6 各自为一个独立集合。 步骤 3：贪心遍历选边（核心步骤） 遍历排序后的所有边，对每条边执行以下判断：\n判环：用并查集的 find 方法，查找当前边的两个村落的「根节点」： 若两个根节点相同：说明两个村落已连通，选这条边会形成环，跳过。 若两个根节点不同：说明两个村落未连通，选这条边不会形成环，执行下一步。 合并 + 累加成本： 用并查集的 union 方法，将两个村落的集合合并（让它们连通）。 累加这条边的成本到总费用中。 记录已选边数（生成树需要「N-1」条边）。 步骤 4：终止条件与结果判断 终止条件：当已选边数达到「N-1」时，停止遍历（生成树已形成，无需继续选边）。 结果判断： 若已选边数 = N-1：总累加成本即为 “村村通” 的最低成本。 若遍历完所有边，已选边数 \u0026lt; N-1：说明村落无法全部连通（如存在多个孤立的连通分量），输出 - 1。 关键支撑：并查集的作用 Kruskal 算法的效率依赖并查集的两个核心操作（均做了优化）：\nfind(x)：查找节点 x 的根节点，通过「路径压缩」将 x 直接指向根节点，后续查询复杂度近似 O (1)。 union(x,y)：合并 x 和 y 所在的集合（通常简单合并或按秩合并），保证集合管理的高效性。 Kruskal 算法复杂度分析 时间复杂度：主要由「边排序」决定，为 O(M log M)（M 为边数）；并查集的 find/union 操作近似 O (1)，整体复杂度为 O(M log M)。 适用场景：适合稀疏图（边数少），本题中 M≤3N（N≤1000），属于稀疏图，非常适配 Kruskal 算法。 总结 Kruskal 算法的核心可概括为：“排序边 + 查环（并查集）+ 选边（无环则加）”，贪心策略保证了选边的最小成本，并用查集高效避免环的形成，最终得到无环、连通、总权重最小的生成树。\nJava 代码实现 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt; import java.util.Arrays; import java.util.Scanner; // 定义边类，实现Comparable接口用于按权重排序 class Edge implements Comparable\u0026lt;Edge\u0026gt; { int u; // 起点城镇 int v; // 终点城镇 int weight; // 改建成本 public Edge(int u, int v, int weight) { this.u = u; this.v = v; this.weight = weight; } // 按权重升序排序 @Override public int compareTo(Edge o) { return this.weight - o.weight; } } public class Main { private static int[] parent; // 并查集父节点数组 // 查找根节点（带路径压缩，优化查询效率） private static int find(int x) { if (parent[x] != x) { parent[x] = find(parent[x]); // 路径压缩：将节点直接指向根 } return parent[x]; } // 合并两个集合 private static void union(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { parent[rootY] = rootX; // 将y的根节点指向x的根节点 } } public static void main(String[] args) { Scanner scanner = new Scanner(System.in); // 多组测试数据处理 while (scanner.hasNextInt()) { int N = scanner.nextInt(); // 城镇数目 int M = scanner.nextInt(); // 候选道路数目 Edge[] edges = new Edge[M]; // 读取所有候选道路 for (int i = 0; i \u0026lt; M; i++) { int u = scanner.nextInt(); int v = scanner.nextInt(); int weight = scanner.nextInt(); edges[i] = new Edge(u, v, weight); } // 按权重升序排序边 Arrays.sort(edges); // 初始化并查集：每个城镇初始为自身的父节点 parent = new int[N + 1]; // 城镇编号从1到N，索引0不用 for (int i = 1; i \u0026lt;= N; i++) { parent[i] = i; } int selectedEdges = 0; // 已选边数（目标：N-1） int totalCost = 0; // 最小总成本 // 遍历排序后的边，贪心选边 for (Edge edge : edges) { int rootU = find(edge.u); int rootV = find(edge.v); // 若两个城镇不属于同一集合，合并并累加成本 if (rootU != rootV) { union(rootU, rootV); totalCost += edge.weight; selectedEdges++; // 选够N-1条边，提前终止 if (selectedEdges == N - 1) { break; } } } // 输出结果：选够N-1条边则输出总成本，否则输出-1 if (selectedEdges == N - 1) { System.out.println(totalCost); } else { System.out.println(-1); } } scanner.close(); } } \u0026lt;/summary\u0026gt; ","date":1765366210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1765546810,"objectID":"4a1b2e0ccb478f41af0aa3dc0b27a9e5","permalink":"https://noctis-sikong.github.io/post/%E6%9D%91%E6%9D%91%E9%80%9A%E9%97%AE%E9%A2%98/","publishdate":"2025-12-10T19:30:10+08:00","relpermalink":"/post/%E6%9D%91%E6%9D%91%E9%80%9A%E9%97%AE%E9%A2%98/","section":"post","summary":"村村通问题的本质 本题要求计算使所有村落连通的最低公路建设成本，本质是求解最小生成树（MST） 问题。最小生成树的核心是在无向图中选择 N-1 条边（N 为节点数），使得所有节点连通且总权重最小。常用的算法有 Kruskal（克鲁斯卡尔）和 Prim（普里姆），这里选择 Kruskal 算法，因为其通过排序边 + 并查集（Union-Find）的方式实现，逻辑清晰且适配本题数据规模（N≤1000，M≤3N）。\n","tags":null,"title":"村村通问题","type":"post"}]